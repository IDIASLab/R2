##############################
MLPClassifier Full Results
##############################
    hidden_layer_sizes   alpha  learning_rate_init  max_iter  f1_score  accuracy  precision_0  precision_1  recall_0  recall_1
0             (32, 32)  0.0001               0.001        25  0.803566  0.820019     0.853110     0.782749  0.815592  0.825520
1             (32, 32)  0.0001               0.001        50  0.810878  0.830541     0.849698     0.807136  0.843328  0.814654
2             (32, 32)  0.0001               0.001       100  0.810878  0.830541     0.849698     0.807136  0.843328  0.814654
3             (32, 32)  0.0001               0.010        25  0.773976  0.786931     0.838790     0.734392  0.761869  0.818069
4             (32, 32)  0.0001               0.010        50  0.774330  0.793576     0.827209     0.755464  0.793103  0.794163
5             (32, 32)  0.0001               0.010       100  0.774330  0.793576     0.827209     0.755464  0.793103  0.794163
6             (32, 32)  0.0001               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
7             (32, 32)  0.0001               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
8             (32, 32)  0.0001               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
9             (32, 32)  0.0010               0.001        25  0.806861  0.820712     0.861995     0.776406  0.805347  0.839801
10            (32, 32)  0.0010               0.001        50  0.821543  0.837602     0.865409     0.805489  0.837081  0.838249
11            (32, 32)  0.0010               0.001       100  0.822162  0.836910     0.869634     0.800176  0.830085  0.845390
12            (32, 32)  0.0010               0.010        25  0.762318  0.764918     0.849091     0.694112  0.700150  0.845390
13            (32, 32)  0.0010               0.010        50  0.762318  0.764918     0.849091     0.694112  0.700150  0.845390
14            (32, 32)  0.0010               0.010       100  0.762318  0.764918     0.849091     0.694112  0.700150  0.845390
15            (32, 32)  0.0010               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
16            (32, 32)  0.0010               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
17            (32, 32)  0.0010               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
18            (32, 32)  0.0100               0.001        25  0.809149  0.829018     0.848226     0.805538  0.842079  0.812791
19            (32, 32)  0.0100               0.001        50  0.816145  0.834141     0.856925     0.806980  0.841079  0.825520
20            (32, 32)  0.0100               0.001       100  0.823049  0.838017     0.869520     0.802418  0.832584  0.844769
21            (32, 32)  0.0100               0.010        25  0.481101  0.566662     0.598821     0.516186  0.660170  0.450481
22            (32, 32)  0.0100               0.010        50  0.481101  0.566662     0.598821     0.516186  0.660170  0.450481
23            (32, 32)  0.0100               0.010       100  0.481101  0.566662     0.598821     0.516186  0.660170  0.450481
24            (32, 32)  0.0100               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
25            (32, 32)  0.0100               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
26            (32, 32)  0.0100               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
27            (32, 32)  0.1000               0.001        25  0.696695  0.740828     0.749298     0.728567  0.799850  0.667495
28            (32, 32)  0.1000               0.001        50  0.726638  0.750519     0.785566     0.710472  0.756122  0.743558
29            (32, 32)  0.1000               0.001       100  0.726638  0.750519     0.785566     0.710472  0.756122  0.743558
30            (32, 32)  0.1000               0.010        25  0.357157  0.557940     0.573854     0.508018  0.785357  0.275380
31            (32, 32)  0.1000               0.010        50  0.357157  0.557940     0.573854     0.508018  0.785357  0.275380
32            (32, 32)  0.1000               0.010       100  0.357157  0.557940     0.573854     0.508018  0.785357  0.275380
33            (32, 32)  0.1000               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
34            (32, 32)  0.1000               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
35            (32, 32)  0.1000               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
36            (64, 64)  0.0001               0.001        25  0.814379  0.834141     0.851378     0.812867  0.848826  0.815896
37            (64, 64)  0.0001               0.001        50  0.820016  0.840648     0.852062     0.826087  0.862069  0.814033
38            (64, 64)  0.0001               0.001       100  0.817614  0.838294     0.850743     0.822495  0.858821  0.812791
39            (64, 64)  0.0001               0.010        25  0.770018  0.788454     0.825526     0.747298  0.783858  0.794163
40            (64, 64)  0.0001               0.010        50  0.787387  0.807698     0.834058     0.776570  0.815092  0.798510
41            (64, 64)  0.0001               0.010       100  0.787387  0.807698     0.834058     0.776570  0.815092  0.798510
42            (64, 64)  0.0001               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
43            (64, 64)  0.0001               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
44            (64, 64)  0.0001               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
45            (64, 64)  0.0010               0.001        25  0.810593  0.830680     0.848508     0.808714  0.845327  0.812481
46            (64, 64)  0.0010               0.001        50  0.815334  0.835941     0.849764     0.818523  0.855072  0.812170
47            (64, 64)  0.0010               0.001       100  0.826256  0.845355     0.859278     0.827930  0.862069  0.824589
48            (64, 64)  0.0010               0.010        25  0.717712  0.729475     0.790744     0.671170  0.695902  0.771189
49            (64, 64)  0.0010               0.010        50  0.717712  0.729475     0.790744     0.671170  0.695902  0.771189
50            (64, 64)  0.0010               0.010       100  0.717712  0.729475     0.790744     0.671170  0.695902  0.771189
51            (64, 64)  0.0010               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
52            (64, 64)  0.0010               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
53            (64, 64)  0.0010               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
54            (64, 64)  0.0100               0.001        25  0.820325  0.830126     0.883817     0.776330  0.798351  0.869606
55            (64, 64)  0.0100               0.001        50  0.827893  0.839402     0.883639     0.792839  0.817841  0.866191
56            (64, 64)  0.0100               0.001       100  0.825748  0.845217     0.857994     0.829108  0.863568  0.822415
57            (64, 64)  0.0100               0.010        25  0.645330  0.567354     0.768524     0.508587  0.313593  0.882645
58            (64, 64)  0.0100               0.010        50  0.645330  0.567354     0.768524     0.508587  0.313593  0.882645
59            (64, 64)  0.0100               0.010       100  0.645330  0.567354     0.768524     0.508587  0.313593  0.882645
60            (64, 64)  0.0100               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
61            (64, 64)  0.0100               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
62            (64, 64)  0.0100               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
63            (64, 64)  0.1000               0.001        25  0.702983  0.738059     0.758959     0.711019  0.772614  0.695126
64            (64, 64)  0.1000               0.001        50  0.722579  0.754534     0.774981     0.728391  0.784858  0.716858
65            (64, 64)  0.1000               0.001       100  0.722579  0.754534     0.774981     0.728391  0.784858  0.716858
66            (64, 64)  0.1000               0.010        25  0.410084  0.562647     0.582826     0.514527  0.741129  0.340888
67            (64, 64)  0.1000               0.010        50  0.410084  0.562647     0.582826     0.514527  0.741129  0.340888
68            (64, 64)  0.1000               0.010       100  0.410084  0.562647     0.582826     0.514527  0.741129  0.340888
69            (64, 64)  0.1000               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
70            (64, 64)  0.1000               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
71            (64, 64)  0.1000               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
72          (128, 128)  0.0001               0.001        25  0.798756  0.820850     0.837319     0.800249  0.839830  0.797268
73          (128, 128)  0.0001               0.001        50  0.821379  0.838987     0.860920     0.812766  0.846077  0.830177
74          (128, 128)  0.0001               0.001       100  0.821379  0.838987     0.860920     0.812766  0.846077  0.830177
75          (128, 128)  0.0001               0.010        25  0.770396  0.781808     0.838827     0.725775  0.750375  0.820863
76          (128, 128)  0.0001               0.010        50  0.795863  0.811436     0.849947     0.769342  0.801099  0.824278
77          (128, 128)  0.0001               0.010       100  0.812436  0.821265     0.880652     0.763517  0.783608  0.868053
78          (128, 128)  0.0001               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
79          (128, 128)  0.0001               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
80          (128, 128)  0.0001               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
81          (128, 128)  0.0010               0.001        25  0.806583  0.829157     0.840551     0.814498  0.853573  0.798820
82          (128, 128)  0.0010               0.001        50  0.823847  0.837602     0.873712     0.797848  0.826337  0.851599
83          (128, 128)  0.0010               0.001       100  0.822039  0.838571     0.864337     0.808466  0.840580  0.836076
84          (128, 128)  0.0010               0.010        25  0.761289  0.765056     0.845577     0.695988  0.704648  0.840112
85          (128, 128)  0.0010               0.010        50  0.773916  0.782085     0.848650     0.720128  0.738381  0.836386
86          (128, 128)  0.0010               0.010       100  0.773916  0.782085     0.848650     0.720128  0.738381  0.836386
87          (128, 128)  0.0010               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
88          (128, 128)  0.0010               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
89          (128, 128)  0.0010               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
90          (128, 128)  0.0100               0.001        25  0.809696  0.825003     0.860074     0.786027  0.817091  0.834834
91          (128, 128)  0.0100               0.001        50  0.823349  0.840371     0.863671     0.812765  0.845327  0.834213
92          (128, 128)  0.0100               0.001       100  0.823349  0.840371     0.863671     0.812765  0.845327  0.834213
93          (128, 128)  0.0100               0.010        25  0.627877  0.644054     0.702405     0.588124  0.620440  0.673393
94          (128, 128)  0.0100               0.010        50  0.627877  0.644054     0.702405     0.588124  0.620440  0.673393
95          (128, 128)  0.0100               0.010       100  0.627877  0.644054     0.702405     0.588124  0.620440  0.673393
96          (128, 128)  0.0100               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
97          (128, 128)  0.0100               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
98          (128, 128)  0.0100               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
99          (128, 128)  0.1000               0.001        25  0.703605  0.722276     0.771491     0.671271  0.708646  0.739211
100         (128, 128)  0.1000               0.001        50  0.716659  0.733213     0.784793     0.680726  0.714393  0.756597
101         (128, 128)  0.1000               0.001       100  0.716659  0.733213     0.784793     0.680726  0.714393  0.756597
102         (128, 128)  0.1000               0.010        25  0.337046  0.563201     0.574494     0.521456  0.816092  0.248991
103         (128, 128)  0.1000               0.010        50  0.337046  0.563201     0.574494     0.521456  0.816092  0.248991
104         (128, 128)  0.1000               0.010       100  0.337046  0.563201     0.574494     0.521456  0.816092  0.248991
105         (128, 128)  0.1000               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
106         (128, 128)  0.1000               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
107         (128, 128)  0.1000               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
108         (256, 256)  0.0001               0.001        25  0.812452  0.831510     0.852086     0.806610  0.842079  0.818379
109         (256, 256)  0.0001               0.001        50  0.821292  0.838710     0.861401     0.811704  0.844828  0.831108
110         (256, 256)  0.0001               0.001       100  0.821292  0.838710     0.861401     0.811704  0.844828  0.831108
111         (256, 256)  0.0001               0.010        25  0.775191  0.800775     0.816968     0.780189  0.825337  0.770258
112         (256, 256)  0.0001               0.010        50  0.800790  0.818496     0.848304     0.784226  0.818841  0.818069
113         (256, 256)  0.0001               0.010       100  0.802032  0.821958     0.843972     0.795420  0.832584  0.808755
114         (256, 256)  0.0001               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
115         (256, 256)  0.0001               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
116         (256, 256)  0.0001               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
117         (256, 256)  0.0010               0.001        25  0.818266  0.836356     0.857868     0.810539  0.844578  0.826141
118         (256, 256)  0.0010               0.001        50  0.821717  0.841340     0.855578     0.823511  0.858571  0.819932
119         (256, 256)  0.0010               0.001       100  0.821717  0.841340     0.855578     0.823511  0.858571  0.819932
120         (256, 256)  0.0010               0.010        25  0.718295  0.745674     0.775937     0.709697  0.760620  0.727103
121         (256, 256)  0.0010               0.010        50  0.749188  0.753980     0.831200     0.686853  0.697651  0.823968
122         (256, 256)  0.0010               0.010       100  0.749188  0.753980     0.831200     0.686853  0.697651  0.823968
123         (256, 256)  0.0010               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
124         (256, 256)  0.0010               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
125         (256, 256)  0.0010               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
126         (256, 256)  0.0100               0.001        25  0.807061  0.829018     0.842196     0.812264  0.850825  0.801925
127         (256, 256)  0.0100               0.001        50  0.824423  0.839956     0.868653     0.807018  0.837831  0.842595
128         (256, 256)  0.0100               0.001       100  0.830290  0.841756     0.885414     0.795674  0.820590  0.868053
129         (256, 256)  0.0100               0.010        25  0.085546  0.570815     0.563935     0.857988  0.994003  0.045017
130         (256, 256)  0.0100               0.010        50  0.085546  0.570815     0.563935     0.857988  0.994003  0.045017
131         (256, 256)  0.0100               0.010       100  0.085546  0.570815     0.563935     0.857988  0.994003  0.045017
132         (256, 256)  0.0100               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
133         (256, 256)  0.0100               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
134         (256, 256)  0.0100               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
135         (256, 256)  0.1000               0.001        25  0.690336  0.708985     0.759847     0.656854  0.694153  0.727414
136         (256, 256)  0.1000               0.001        50  0.707858  0.737505     0.766313     0.702661  0.757121  0.713133
137         (256, 256)  0.1000               0.001       100  0.700601  0.737782     0.755949     0.713688  0.777861  0.687985
138         (256, 256)  0.1000               0.010        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
139         (256, 256)  0.1000               0.010        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
140         (256, 256)  0.1000               0.010       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
141         (256, 256)  0.1000               0.100        25  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
142         (256, 256)  0.1000               0.100        50  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000
143         (256, 256)  0.1000               0.100       100  0.000000  0.554063     0.554063     0.000000  1.000000  0.000000

Best Parameters for MLPClassifier:
{'hidden_layer_sizes': (256, 256), 'alpha': 0.01, 'learning_rate_init': 0.001, 'max_iter': 100, 'f1_score': 0.8302895322939866, 'accuracy': 0.8417555032534958, 'precision_0': 0.8854138581827986, 'precision_1': 0.7956744450768355, 'recall_0': 0.8205897051474262, 'recall_1': 0.8680533995653523}

Classification Report for Best MLPClassifier:
              precision    recall  f1-score   support

           0       0.89      0.82      0.85      4002
           1       0.80      0.87      0.83      3221

    accuracy                           0.84      7223
   macro avg       0.84      0.84      0.84      7223
weighted avg       0.85      0.84      0.84      7223



##############################
XGBClassifier Full Results
##############################
    n_estimators  max_depth  learning_rate  f1_score  accuracy  precision_0  precision_1  recall_0  recall_1
0            100          5           0.01  0.418878  0.657345     0.623444     0.859345  0.963518  0.276933
1            100          5           0.10  0.624443  0.720061     0.695652     0.777161  0.879560  0.521888
2            100          5           0.20  0.695358  0.751073     0.742624     0.765386  0.842829  0.637069
3            100         10           0.01  0.592549  0.715354     0.680252     0.819178  0.917541  0.464142
4            100         10           0.10  0.742083  0.781254     0.780454     0.782444  0.842079  0.705681
5            100         10           0.20  0.752668  0.784992     0.793998     0.772727  0.826337  0.733623
6            100         15           0.01  0.644151  0.738890     0.705677     0.821068  0.907046  0.529960
7            100         15           0.10  0.741283  0.775024     0.785491     0.760784  0.817091  0.722757
8            100         15           0.20  0.743489  0.775024     0.789243     0.756262  0.810345  0.731139
9            200          5           0.01  0.515681  0.681434     0.649394     0.800654  0.923788  0.380317
10           200          5           0.10  0.692481  0.753703     0.738571     0.781201  0.859820  0.621857
11           200          5           0.20  0.758445  0.790115     0.798225     0.779051  0.831334  0.738901
12           200         10           0.01  0.628159  0.729060     0.697356     0.809500  0.902799  0.513195
13           200         10           0.10  0.764911  0.794822     0.804348     0.782030  0.832084  0.748525
14           200         10           0.20  0.766379  0.794130     0.808286     0.775763  0.823838  0.757218
15           200         15           0.01  0.678469  0.751073     0.727123     0.800084  0.881559  0.588948
16           200         15           0.10  0.751101  0.780977     0.795988     0.761404  0.813093  0.741074
17           200         15           0.20  0.750510  0.779731     0.796410     0.758238  0.809345  0.742937
18           300          5           0.01  0.545123  0.689464     0.659532     0.785965  0.908546  0.417262
19           300          5           0.10  0.739875  0.781254     0.777117     0.787592  0.848576  0.697609
20           300          5           0.20  0.774204  0.801744     0.813262     0.786607  0.833583  0.762186
21           300         10           0.01  0.652527  0.739167     0.710872     0.803726  0.892054  0.549208
22           300         10           0.10  0.774173  0.801468     0.813630     0.785554  0.832334  0.763117
23           300         10           0.20  0.768388  0.795099     0.811051     0.774692  0.821589  0.762186
24           300         15           0.01  0.701038  0.760764     0.743782     0.791716  0.866817  0.628997
25           300         15           0.10  0.758815  0.786931     0.803101     0.766139  0.815342  0.751630
26           300         15           0.20  0.756486  0.784300     0.802027     0.761725  0.810845  0.751319

Best Parameters for XGBClassifier:
{'n_estimators': 300.0, 'max_depth': 5.0, 'learning_rate': 0.2, 'f1_score': 0.7742037212235888, 'accuracy': 0.8017444275231899, 'precision_0': 0.8132618235007314, 'precision_1': 0.7866068567766742, 'recall_0': 0.8335832083958021, 'recall_1': 0.7621856566283762}

Classification Report for Best XGBClassifier:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      4002
           1       0.79      0.76      0.77      3221

    accuracy                           0.80      7223
   macro avg       0.80      0.80      0.80      7223
weighted avg       0.80      0.80      0.80      7223



##############################
LGBMClassifier Full Results
##############################
    n_estimators  max_depth  learning_rate  is_unbalance  f1_score  accuracy  precision_0  precision_1  recall_0  recall_1
0            100          5           0.01          True  0.527233  0.669528     0.649676     0.728118  0.875812  0.413226
1            100          5           0.01         False  0.442042  0.664128     0.629265     0.852706  0.958521  0.298355
2            100          5           0.10          True  0.677922  0.727952     0.734515     0.718056  0.797101  0.642037
3            100          5           0.10         False  0.625771  0.722968     0.696292     0.786924  0.886807  0.519404
4            100          5           0.20          True  0.732551  0.760210     0.786038     0.728725  0.779360  0.736417
5            100          5           0.20         False  0.687780  0.748858     0.736081     0.771727  0.852324  0.620304
6            100         10           0.01          True  0.573574  0.685449     0.669077     0.725202  0.855322  0.474387
7            100         10           0.01         False  0.525705  0.683234     0.652491     0.791017  0.916292  0.393667
8            100         10           0.10          True  0.725463  0.755642     0.778580     0.726933  0.781109  0.723999
9            100         10           0.10         False  0.670605  0.745258     0.722520     0.791966  0.877061  0.581496
10           100         10           0.20          True  0.754671  0.776409     0.809117     0.738846  0.780610  0.771189
11           100         10           0.20         False  0.731967  0.777239     0.769421     0.789720  0.853823  0.682086
12           100         15           0.01          True  0.573795  0.686557     0.669330     0.728838  0.858321  0.473145
13           100         15           0.01         False  0.529109  0.683096     0.653412     0.784146  0.911544  0.399255
14           100         15           0.10          True  0.727558  0.759657     0.778242     0.735639  0.791854  0.719652
15           100         15           0.10         False  0.665234  0.741243     0.719399     0.786198  0.873813  0.576529
16           100         15           0.20          True  0.754912  0.777239     0.808456     0.741029  0.783608  0.769326
17           100         15           0.20         False  0.721972  0.768933     0.762666     0.778936  0.846327  0.672772
18           200          5           0.01          True  0.577999  0.682403     0.670527     0.709255  0.839080  0.487737
19           200          5           0.01         False  0.513058  0.679911     0.648350     0.797642  0.922789  0.378143
20           200          5           0.10          True  0.724402  0.755919     0.776625     0.729534  0.785357  0.719342
21           200          5           0.10         False  0.697054  0.757995     0.741121     0.788937  0.865567  0.624340
22           200          5           0.20          True  0.771715  0.788592     0.829561     0.744233  0.778361  0.801304
23           200          5           0.20         False  0.749839  0.784577     0.789536     0.777593  0.833333  0.723999
24           200         10           0.01          True  0.614451  0.700817     0.690225     0.722315  0.834583  0.534617
25           200         10           0.01         False  0.561895  0.692787     0.665737     0.771692  0.894803  0.441788
26           200         10           0.10          True  0.761732  0.782085     0.816311     0.743279  0.782859  0.781124
27           200         10           0.10         False  0.719919  0.769902     0.759424     0.787320  0.855822  0.663148
28           200         10           0.20          True  0.776755  0.795237     0.830322     0.755875  0.792354  0.798820
29           200         10           0.20         False  0.759730  0.793161     0.796735     0.788121  0.841329  0.733313
30           200         15           0.01          True  0.617564  0.700955     0.692035     0.718583  0.829335  0.541447
31           200         15           0.01         False  0.566458  0.692925     0.667417     0.764644  0.888556  0.449860
32           200         15           0.10          True  0.757885  0.780008     0.810873     0.744165  0.786357  0.772120
33           200         15           0.10         False  0.716104  0.768379     0.755878     0.789671  0.859570  0.655076
34           200         15           0.20          True  0.770297  0.788869     0.825493     0.748098  0.784858  0.793853
35           200         15           0.20         False  0.752498  0.787346     0.790939     0.782245  0.837581  0.724930
36           300          5           0.01          True  0.602039  0.691956     0.683083     0.710127  0.828336  0.522509
37           300          5           0.01         False  0.544130  0.688218     0.658975     0.781850  0.906297  0.417262
38           300          5           0.10          True  0.763790  0.783608     0.818657     0.744111  0.782859  0.784539
39           300          5           0.10         False  0.732338  0.776547     0.770503     0.786045  0.849825  0.685501
40           300          5           0.20          True  0.781998  0.798145     0.838658     0.754254  0.787106  0.811860
41           300          5           0.20         False  0.769255  0.798006     0.808542     0.784010  0.832584  0.755045
42           300         10           0.01          True  0.646001  0.713831     0.710098     0.720397  0.817091  0.585532
43           300         10           0.01         False  0.594824  0.709539     0.680782     0.786919  0.895802  0.478112
44           300         10           0.10          True  0.768094  0.787069     0.823190     0.746702  0.784108  0.790748
45           300         10           0.10         False  0.749551  0.787761     0.785566     0.791034  0.848576  0.712201
46           300         10           0.20          True  0.779193  0.798422     0.830649     0.761637  0.799100  0.797578
47           300         10           0.20         False  0.768324  0.798699     0.805662     0.789198  0.839080  0.748525
48           300         15           0.01          True  0.646758  0.713415     0.710733     0.718075  0.814093  0.588327
49           300         15           0.01         False  0.594895  0.707739     0.680680     0.778894  0.890055  0.481217
50           300         15           0.10          True  0.772025  0.791499     0.825169     0.753323  0.791354  0.791680
51           300         15           0.10         False  0.745613  0.785269     0.781919     0.790334  0.849325  0.705681
52           300         15           0.20          True  0.777007  0.795376     0.830713     0.755797  0.792104  0.799441
53           300         15           0.20         False  0.764041  0.794684     0.802837     0.783616  0.834333  0.745421

Best Parameters for LGBMClassifier:
{'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.2, 'is_unbalance': True, 'f1_score': 0.7819976076555024, 'accuracy': 0.7981448151737505, 'precision_0': 0.8386581469648562, 'precision_1': 0.7542543986155177, 'recall_0': 0.7871064467766117, 'recall_1': 0.8118596709096554}

Classification Report for Best LGBMClassifier:
              precision    recall  f1-score   support

           0       0.84      0.79      0.81      4002
           1       0.75      0.81      0.78      3221

    accuracy                           0.80      7223
   macro avg       0.80      0.80      0.80      7223
weighted avg       0.80      0.80      0.80      7223



##############################
Ensemble Model Performance
##############################
Ensemble Accuracy: 0.8520
Ensemble Classification Report:
              precision    recall  f1-score   support

           0       0.87      0.86      0.87      4002
           1       0.83      0.84      0.83      3221

    accuracy                           0.85      7223
   macro avg       0.85      0.85      0.85      7223
weighted avg       0.85      0.85      0.85      7223
