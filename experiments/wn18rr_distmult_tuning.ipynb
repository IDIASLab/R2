{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X5k8WFGpevba"
      },
      "outputs": [],
      "source": [
        "#!pip uninstall scikit-learn\n",
        "#!pip install scikit-learn==1.5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7uPMNxqSZXX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,roc_curve,auc,classification_report,make_scorer\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from link_prediction import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v4rpvOhwSxVE"
      },
      "outputs": [],
      "source": [
        "#Load the entity embeddings dict\n",
        "with open(\"wn18rr_distmult_entity_embeddings.pkl\", \"rb\") as f:\n",
        "    entity_embeddings = pickle.load(f)\n",
        "#Load the predicate embeddings dict\n",
        "with open(\"wn18rr_distmult_predicate_embeddings.pkl\", \"rb\") as f:\n",
        "    predicate_embeddings = pickle.load(f)\n",
        "\n",
        "train_triples = pd.read_csv('wn18rr_train.txt', dtype=str, sep='\\t', header=None, names=['head', 'relation', 'tail'])\n",
        "test_triples = pd.read_csv('wn18rr_test.txt', dtype=str, sep='\\t', header=None, names=['head', 'relation', 'tail'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUmY423XWjUn"
      },
      "source": [
        "**Create Negative Samples**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VYaBwd_S6Ni",
        "outputId": "0a5aaded-c205-452d-a3a3-9a00bbafe933"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing triples: 100%|██████████| 86835/86835 [01:02<00:00, 1385.07triple/s]\n",
            "Processing triples: 100%|██████████| 86835/86835 [01:03<00:00, 1370.39triple/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62544\n",
            "40938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "training_object=Training(entity_embeddings,predicate_embeddings,train_triples,test_triples, model='DistMult')\n",
        "tail_df = training_object.create_training_data_filtered(n=1, creating_for=\"tail\")\n",
        "head_df = training_object.create_training_data_filtered(n=1, creating_for=\"head\")\n",
        "print(len(tail_df))\n",
        "print(len(head_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8js9F5XPTLq3"
      },
      "source": [
        "**Prepare Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "qOXSQ_U0TEOd",
        "outputId": "4fb65a71-7b47-4165-adb3-a4365e9437dd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>95568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>86835</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "0    95568\n",
              "1    86835\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_triples['label']=1\n",
        "train_df = pd.concat([head_df,tail_df,train_triples], axis=0)\n",
        "# Reset the index\n",
        "train_df.reset_index(drop=True, inplace=True)\n",
        "# Drop duplicate rows\n",
        "train_df.drop_duplicates(inplace=True)\n",
        "# Step 1: Prepare the training data\n",
        "train_df['embedding'] = train_df.apply(lambda row: training_object.get_embedding(row).cpu().numpy(), axis=1)\n",
        "X_train = np.vstack(train_df['embedding'].values)  # Stack embeddings into a matrix\n",
        "y_train = train_df['label'].values  # Labels\n",
        "# Step 1: Split the data into training and test sets with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    np.vstack(train_df['embedding'].values),  # Embeddings matrix\n",
        "    train_df['label'].values,                # Labels\n",
        "    test_size=0.1,                           # 10% of the data for testing\n",
        "    random_state=42,                         # For reproducibility\n",
        "    stratify=train_df['label'].values        # Maintain label distribution\n",
        ")\n",
        "train_df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BewwL105Telw"
      },
      "source": [
        "**Set Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGzknXtLORux"
      },
      "source": [
        "**MLP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6X9xEgUjHQDG"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.simplefilter(\"ignore\", ConvergenceWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ep1UaH6TPR_",
        "outputId": "1f1906a1-b904-4afe-8258-73a1f0c830ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters for MLP: {'hidden_layer_sizes': (128, 128), 'alpha': 0.0001, 'learning_rate_init': 0.001, 'max_iter': 100, 'f1_score': 0.7022650180544917, 'accuracy': 0.7016610931418233, 'precision_0': 0.7379437955360241, 'precision_1': 0.6689597665207422, 'recall_0': 0.6676781416762583, 'recall_1': 0.739060340856748}\n"
          ]
        }
      ],
      "source": [
        "param_grid_mlp = {\n",
        "    'hidden_layer_sizes': [ (64, 64), (128, 128), (256, 256)],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'learning_rate_init': [0.001, 0.01],\n",
        "    'max_iter': [50, 100]\n",
        "}\n",
        "\n",
        "results_mlp = []\n",
        "for hidden_layer_sizes in param_grid_mlp['hidden_layer_sizes']:\n",
        "    for alpha in param_grid_mlp['alpha']:\n",
        "        for learning_rate_init in param_grid_mlp['learning_rate_init']:\n",
        "            for max_iter in param_grid_mlp['max_iter']:\n",
        "                mlp = MLPClassifier(\n",
        "                    hidden_layer_sizes=hidden_layer_sizes,\n",
        "                    alpha=alpha,\n",
        "                    learning_rate_init=learning_rate_init,\n",
        "                    max_iter=max_iter,\n",
        "                    solver='adam',\n",
        "                    early_stopping=True,\n",
        "                    batch_size=32,\n",
        "                    random_state=42\n",
        "                )\n",
        "                mlp.fit(X_train, y_train)\n",
        "                preds = mlp.predict(X_test)\n",
        "\n",
        "                # Calculate metrics\n",
        "                score_f1 = f1_score(y_test, preds)\n",
        "                acc = accuracy_score(y_test, preds)\n",
        "                precisions = precision_score(y_test, preds, average=None, zero_division=0)\n",
        "                recalls = recall_score(y_test, preds, average=None, zero_division=0)\n",
        "\n",
        "                results_mlp.append({\n",
        "                    'hidden_layer_sizes': hidden_layer_sizes,\n",
        "                    'alpha': alpha,\n",
        "                    'learning_rate_init': learning_rate_init,\n",
        "                    'max_iter': max_iter,\n",
        "                    'f1_score': score_f1,\n",
        "                    'accuracy': acc,\n",
        "                    'precision_0': precisions[0],\n",
        "                    'precision_1': precisions[1],\n",
        "                    'recall_0': recalls[0],\n",
        "                    'recall_1': recalls[1]\n",
        "                })\n",
        "\n",
        "df_results_mlp = pd.DataFrame(results_mlp)\n",
        "\n",
        "best_mlp_params = df_results_mlp.sort_values(by='f1_score', ascending=False).iloc[0].to_dict()\n",
        "print(\"Best parameters for MLP:\", best_mlp_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9YJEh-WOP07"
      },
      "source": [
        "**XGB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlTfpHrPMA7v",
        "outputId": "0e7778ef-2165-488e-c9e9-3155537dff74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters for XGBClassifier: {'n_estimators': 300.0, 'max_depth': 5.0, 'learning_rate': 0.2, 'f1_score': 0.8811053619150508, 'accuracy': 0.8853681267474371, 'precision_0': 0.8997644035125294, 'precision_1': 0.8702684488374706, 'recall_0': 0.8791461755781103, 'recall_1': 0.8922155688622755}\n"
          ]
        }
      ],
      "source": [
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    # 'scale_pos_weight': [0.5, 1, 2],  # commented out as provided\n",
        "    'learning_rate': [0.01, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "\n",
        "results_xgb = []\n",
        "for n_estimators in param_grid_xgb['n_estimators']:\n",
        "    for max_depth in param_grid_xgb['max_depth']:\n",
        "        for learning_rate in param_grid_xgb['learning_rate']:\n",
        "            xgb = XGBClassifier(\n",
        "                n_estimators=n_estimators,\n",
        "                max_depth=max_depth,\n",
        "                learning_rate=learning_rate,\n",
        "                random_state=42,\n",
        "            )\n",
        "            xgb.fit(X_train, y_train)\n",
        "            preds = xgb.predict(X_test)\n",
        "\n",
        "            # Calculate metrics\n",
        "            score_f1 = f1_score(y_test, preds)\n",
        "            acc = accuracy_score(y_test, preds)\n",
        "            precisions = precision_score(y_test, preds, average=None, zero_division=0)\n",
        "            recalls = recall_score(y_test, preds, average=None, zero_division=0)\n",
        "\n",
        "            results_xgb.append({\n",
        "                'n_estimators': n_estimators,\n",
        "                'max_depth': max_depth,\n",
        "                'learning_rate': learning_rate,\n",
        "                'f1_score': score_f1,\n",
        "                'accuracy': acc,\n",
        "                'precision_0': precisions[0],\n",
        "                'precision_1': precisions[1],\n",
        "                'recall_0': recalls[0],\n",
        "                'recall_1': recalls[1]\n",
        "            })\n",
        "\n",
        "df_results_xgb = pd.DataFrame(results_xgb)\n",
        "best_xgb_params = df_results_xgb.sort_values(by='f1_score', ascending=False).iloc[0].to_dict()\n",
        "print(\"Best parameters for XGBClassifier:\", best_xgb_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBawiIGpOUxY"
      },
      "source": [
        "**LGBM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKdY6e6LMCG8",
        "outputId": "e3a67b27-ac8d-4171-9b25-e44ac7b86ed3"
      },
      "outputs": [],
      "source": [
        "param_grid_lgbm = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'is_unbalance': [True, False]\n",
        "}\n",
        "\n",
        "results_lgbm = []\n",
        "for n_estimators in param_grid_lgbm['n_estimators']:\n",
        "    for max_depth in param_grid_lgbm['max_depth']:\n",
        "        for learning_rate in param_grid_lgbm['learning_rate']:\n",
        "            for is_unbalance in param_grid_lgbm['is_unbalance']:\n",
        "                lgbm = LGBMClassifier(\n",
        "                    n_estimators=n_estimators,\n",
        "                    max_depth=max_depth,\n",
        "                    learning_rate=learning_rate,\n",
        "                    is_unbalance=is_unbalance,\n",
        "                    random_state=42\n",
        "                )\n",
        "                lgbm.fit(X_train, y_train)\n",
        "                preds = lgbm.predict(X_test)\n",
        "\n",
        "                # Calculate metrics\n",
        "                score_f1 = f1_score(y_test, preds)\n",
        "                acc = accuracy_score(y_test, preds)\n",
        "                precisions = precision_score(y_test, preds, average=None, zero_division=0)\n",
        "                recalls = recall_score(y_test, preds, average=None, zero_division=0)\n",
        "\n",
        "                results_lgbm.append({\n",
        "                    'n_estimators': n_estimators,\n",
        "                    'max_depth': max_depth,\n",
        "                    'learning_rate': learning_rate,\n",
        "                    'is_unbalance': is_unbalance,\n",
        "                    'f1_score': score_f1,\n",
        "                    'accuracy': acc,\n",
        "                    'precision_0': precisions[0],\n",
        "                    'precision_1': precisions[1],\n",
        "                    'recall_0': recalls[0],\n",
        "                    'recall_1': recalls[1]\n",
        "                })\n",
        "\n",
        "df_results_lgbm = pd.DataFrame(results_lgbm)\n",
        "best_lgbm_params = df_results_lgbm.sort_values(by='f1_score', ascending=False).iloc[0].to_dict()\n",
        "print(\"Best parameters for LGBM:\", best_lgbm_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3wpa-6XTijx"
      },
      "source": [
        "**Train Ensemble**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh_nSA9ATkra",
        "outputId": "dde94268-64fd-4406-a31d-c040ef6d2ab6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 78151, number of negative: 86011\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.235843 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 52200\n",
            "[LightGBM] [Info] Number of data points in the train set: 164162, number of used features: 300\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.476060 -> initscore=-0.095832\n",
            "[LightGBM] [Info] Start training from score -0.095832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Best MLPClassifier\n",
        "best_mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=best_mlp_params['hidden_layer_sizes'],\n",
        "    alpha=best_mlp_params['alpha'],\n",
        "    learning_rate_init=best_mlp_params['learning_rate_init'],\n",
        "    max_iter=best_mlp_params['max_iter'],\n",
        "    solver='adam',\n",
        "    early_stopping=True,\n",
        "    batch_size=32,\n",
        "    random_state=42\n",
        ")\n",
        "best_mlp.fit(X_train, y_train)\n",
        "preds_mlp = best_mlp.predict(X_test)\n",
        "report_mlp = classification_report(y_test, preds_mlp)\n",
        "\n",
        "# Best XGBClassifier\n",
        "best_xgb = XGBClassifier(\n",
        "    n_estimators=int(best_xgb_params['n_estimators']),\n",
        "    max_depth=int(best_xgb_params['max_depth']),\n",
        "    learning_rate=float(best_xgb_params['learning_rate']),\n",
        "    random_state=42,\n",
        ")\n",
        "best_xgb.fit(X_train, y_train)\n",
        "preds_xgb = best_xgb.predict(X_test)\n",
        "report_xgb = classification_report(y_test, preds_xgb)\n",
        "\n",
        "# Best LGBMClassifier\n",
        "best_lgbm = LGBMClassifier(\n",
        "    n_estimators=best_lgbm_params['n_estimators'],\n",
        "    max_depth=best_lgbm_params['max_depth'],\n",
        "    learning_rate=best_lgbm_params['learning_rate'],\n",
        "    is_unbalance=best_lgbm_params['is_unbalance'],\n",
        "    random_state=42\n",
        ")\n",
        "best_lgbm.fit(X_train, y_train)\n",
        "preds_lgbm = best_lgbm.predict(X_test)\n",
        "report_lgbm = classification_report(y_test, preds_lgbm)\n",
        "\n",
        "######################################\n",
        "# Ensemble the best models using VotingClassifier\n",
        "######################################\n",
        "ensemble_model = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('mlp', best_mlp),\n",
        "        ('xgb', best_xgb),\n",
        "        ('lgbm', best_lgbm)\n",
        "    ],\n",
        "    voting='soft',  # Soft voting uses predicted probabilities\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "ensemble_time = end_time - start_time\n",
        "preds_ensemble = ensemble_model.predict(X_test)\n",
        "ensemble_acc = accuracy_score(y_test, preds_ensemble)\n",
        "report_ensemble = classification_report(y_test, preds_ensemble)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNfjwum7KrCT",
        "outputId": "6123ca9f-1bc5-44ce-a537-23d0f8cd79a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Accuracy: 0.8888767063209254\n",
            "Ensemble Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.89      9557\n",
            "           1       0.88      0.88      0.88      8684\n",
            "\n",
            "    accuracy                           0.89     18241\n",
            "   macro avg       0.89      0.89      0.89     18241\n",
            "weighted avg       0.89      0.89      0.89     18241\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "y_pred_ensemble = ensemble_model.predict(X_test)\n",
        "print(\"Ensemble Accuracy:\", accuracy_score(y_test, y_pred_ensemble))\n",
        "print(\"Ensemble Classification Report:\\n\", classification_report(y_test, y_pred_ensemble))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR3G0jmaKwcO",
        "outputId": "9c277cf9-fd05-4645-db35-a9aa04a993a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to model_results.txt\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/drive/MyDrive/link_prediction/tuning/wn18rr_distmult_tuning.txt\", \"w\") as f:\n",
        "    f.write(\"##############################\\n\")\n",
        "    f.write(\"MLPClassifier Full Results\\n\")\n",
        "    f.write(\"##############################\\n\")\n",
        "    f.write(df_results_mlp.to_string())\n",
        "    f.write(\"\\n\\nBest Parameters for MLPClassifier:\\n\")\n",
        "    f.write(str(best_mlp_params))\n",
        "    f.write(\"\\n\\nClassification Report for Best MLPClassifier:\\n\")\n",
        "    f.write(report_mlp)\n",
        "\n",
        "    f.write(\"\\n\\n\\n##############################\\n\")\n",
        "    f.write(\"XGBClassifier Full Results\\n\")\n",
        "    f.write(\"##############################\\n\")\n",
        "    f.write(df_results_xgb.to_string())\n",
        "    f.write(\"\\n\\nBest Parameters for XGBClassifier:\\n\")\n",
        "    f.write(str(best_xgb_params))\n",
        "    f.write(\"\\n\\nClassification Report for Best XGBClassifier:\\n\")\n",
        "    f.write(report_xgb)\n",
        "\n",
        "    f.write(\"\\n\\n\\n##############################\\n\")\n",
        "    f.write(\"LGBMClassifier Full Results\\n\")\n",
        "    f.write(\"##############################\\n\")\n",
        "    f.write(df_results_lgbm.to_string())\n",
        "    f.write(\"\\n\\nBest Parameters for LGBMClassifier:\\n\")\n",
        "    f.write(str(best_lgbm_params))\n",
        "    f.write(\"\\n\\nClassification Report for Best LGBMClassifier:\\n\")\n",
        "    f.write(report_lgbm)\n",
        "\n",
        "    f.write(\"\\n\\n\\n##############################\\n\")\n",
        "    f.write(\"Ensemble Model Performance\\n\")\n",
        "    f.write(\"##############################\\n\")\n",
        "    f.write(\"Ensemble Accuracy: {:.4f}\\n\".format(ensemble_acc))\n",
        "    f.write(\"Ensemble Classification Report:\\n\")\n",
        "    f.write(report_ensemble)\n",
        "\n",
        "print(\"Results saved to model_results.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaaXmNZEUIB1"
      },
      "source": [
        "**Rerank Hitk**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NklFNH7RUlTM"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bcKVBNzUjTD",
        "outputId": "5e4eea7d-9d51-4782-a58c-548b481e7e33"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Precomputing top-k predictions: 100%|██████████| 3134/3134 [00:22<00:00, 137.29it/s]\n"
          ]
        }
      ],
      "source": [
        "tripleEvaluator=TripleEvaluator(entity_embeddings,predicate_embeddings,train_triples,test_triples, model='DistMult', k=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3XXGZChPo76",
        "outputId": "385166a6-b515-412f-c3ad-d2e1aa191d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k=1 | th=1 | head: 41.94% | tail: 41.86% | overall: 41.90%\n",
            "k=1 | th=2 | head: 31.08% | tail: 31.95% | overall: 31.53%\n",
            "k=1 | th=3 | head: 25.81% | tail: 26.65% | overall: 26.25%\n",
            "k=1 | th=4 | head: 21.87% | tail: 23.60% | overall: 22.78%\n",
            "k=1 | th=5 | head: 18.61% | tail: 20.61% | overall: 19.66%\n",
            "k=1 | th=6 | head: 16.99% | tail: 18.62% | overall: 17.85%\n",
            "k=1 | th=7 | head: 15.50% | tail: 17.02% | overall: 16.30%\n",
            "k=1 | th=8 | head: 15.15% | tail: 16.81% | overall: 16.02%\n",
            "k=1 | th=9 | head: 12.79% | tail: 14.82% | overall: 13.85%\n",
            "k=1 | th=10 | head: 11.64% | tail: 13.65% | overall: 12.70%\n",
            "k=1 | th=20 | head: 8.38% | tail: 10.06% | overall: 9.26%\n",
            "k=1 | th=30 | head: 5.47% | tail: 7.50% | overall: 6.53%\n",
            "k=1 | th=40 | head: 5.70% | tail: 7.32% | overall: 6.55%\n",
            "k=1 | th=50 | head: 4.09% | tail: 5.93% | overall: 5.06%\n",
            "k=3 | th=3 | head: 46.77% | tail: 45.49% | overall: 46.10%\n",
            "k=3 | th=4 | head: 43.63% | tail: 42.40% | overall: 42.98%\n",
            "k=3 | th=5 | head: 39.65% | tail: 39.27% | overall: 39.45%\n",
            "k=3 | th=6 | head: 37.06% | tail: 37.38% | overall: 37.23%\n",
            "k=3 | th=7 | head: 33.60% | tail: 34.83% | overall: 34.24%\n",
            "k=3 | th=8 | head: 32.85% | tail: 33.33% | overall: 33.10%\n",
            "k=3 | th=9 | head: 31.24% | tail: 31.52% | overall: 31.39%\n",
            "k=3 | th=10 | head: 29.27% | tail: 29.96% | overall: 29.63%\n",
            "k=3 | th=20 | head: 19.83% | tail: 21.18% | overall: 20.54%\n",
            "k=3 | th=30 | head: 14.99% | tail: 17.02% | overall: 16.06%\n",
            "k=3 | th=40 | head: 12.59% | tail: 15.28% | overall: 14.00%\n",
            "k=3 | th=50 | head: 10.90% | tail: 13.11% | overall: 12.06%\n",
            "k=5 | th=5 | head: 48.35% | tail: 47.12% | overall: 47.70%\n",
            "k=5 | th=6 | head: 46.77% | tail: 45.84% | overall: 46.28%\n",
            "k=5 | th=7 | head: 44.69% | tail: 44.10% | overall: 44.38%\n",
            "k=5 | th=8 | head: 42.80% | tail: 42.68% | overall: 42.74%\n",
            "k=5 | th=9 | head: 41.03% | tail: 41.58% | overall: 41.32%\n",
            "k=5 | th=10 | head: 39.61% | tail: 40.01% | overall: 39.82%\n",
            "k=5 | th=20 | head: 28.76% | tail: 29.64% | overall: 29.22%\n",
            "k=5 | th=30 | head: 22.54% | tail: 23.92% | overall: 23.26%\n",
            "k=5 | th=40 | head: 18.96% | tail: 21.00% | overall: 20.03%\n",
            "k=5 | th=50 | head: 16.05% | tail: 18.66% | overall: 17.42%\n",
            "k=10 | th=10 | head: 50.87% | tail: 49.08% | overall: 49.93%\n",
            "k=10 | th=11 | head: 50.79% | tail: 48.61% | overall: 49.65%\n",
            "k=10 | th=12 | head: 50.16% | tail: 47.65% | overall: 48.84%\n",
            "k=10 | th=13 | head: 49.13% | tail: 47.30% | overall: 48.17%\n",
            "k=10 | th=14 | head: 48.58% | tail: 46.70% | overall: 47.59%\n",
            "k=10 | th=15 | head: 47.68% | tail: 45.74% | overall: 46.66%\n",
            "k=10 | th=16 | head: 46.70% | tail: 44.88% | overall: 45.74%\n",
            "k=10 | th=17 | head: 46.03% | tail: 44.28% | overall: 45.11%\n",
            "k=10 | th=18 | head: 44.77% | tail: 43.78% | overall: 44.25%\n",
            "k=10 | th=19 | head: 44.18% | tail: 43.14% | overall: 43.63%\n",
            "k=10 | th=20 | head: 43.00% | tail: 42.40% | overall: 42.68%\n",
            "k=10 | th=30 | head: 36.74% | tail: 37.10% | overall: 36.93%\n",
            "k=10 | th=40 | head: 31.98% | tail: 32.44% | overall: 32.23%\n",
            "k=10 | th=50 | head: 27.66% | tail: 29.10% | overall: 28.42%\n"
          ]
        }
      ],
      "source": [
        "# Define the mapping of k values to their respective threshold lists\n",
        "k_threshold_mapping = {\n",
        "    1: [1,2,3,4,5,6,7,8,9,10, 20, 30, 40, 50],\n",
        "    3: [3,4,5,6,7,8,9,10, 20, 30, 40, 50],\n",
        "    5: [5,6,7,8,9, 10,20, 30, 40, 50],\n",
        "    10: [10,11,12,13,14,15,16,17,18,19,20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "# Iterate through the mapping and print results on the fly\n",
        "for k, threshold_values in k_threshold_mapping.items():\n",
        "    for threshold in threshold_values:\n",
        "        # Evaluate for head\n",
        "        total_count_head, hit_count_head = tripleEvaluator.rerank(k=k, model=best_mlp, threshold=threshold, evaluate_for=\"head\")\n",
        "        head_percentage = hit_count_head / total_count_head * 100\n",
        "\n",
        "        # Evaluate for tail\n",
        "        total_count_tail, hit_count_tail = tripleEvaluator.rerank(k=k, model=best_mlp, threshold=threshold, evaluate_for=\"tail\")\n",
        "        tail_percentage = hit_count_tail / total_count_tail * 100\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        overall_hit_count = hit_count_head + hit_count_tail\n",
        "        overall_total_count = total_count_head + total_count_tail\n",
        "        overall_percentage = (overall_hit_count / overall_total_count) * 100\n",
        "\n",
        "        # Print results immediately\n",
        "        print(\n",
        "            f\"k={k} | th={threshold} | \"\n",
        "            f\"head: {head_percentage:.2f}% | tail: {tail_percentage:.2f}% | overall: {overall_percentage:.2f}%\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsbcZJ6fPomJ",
        "outputId": "877d1d44-d7be-464a-f2ec-d7c4994a7b8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k=1 | th=1 | head: 41.94% | tail: 41.86% | overall: 41.90%\n",
            "k=1 | th=2 | head: 42.25% | tail: 41.97% | overall: 42.10%\n",
            "k=1 | th=3 | head: 42.76% | tail: 42.22% | overall: 42.48%\n",
            "k=1 | th=4 | head: 43.04% | tail: 42.18% | overall: 42.59%\n",
            "k=1 | th=5 | head: 42.84% | tail: 42.54% | overall: 42.68%\n",
            "k=1 | th=6 | head: 42.72% | tail: 42.68% | overall: 42.70%\n",
            "k=1 | th=7 | head: 42.68% | tail: 42.54% | overall: 42.61%\n",
            "k=1 | th=8 | head: 42.60% | tail: 42.54% | overall: 42.57%\n",
            "k=1 | th=9 | head: 42.60% | tail: 42.61% | overall: 42.61%\n",
            "k=1 | th=10 | head: 42.60% | tail: 42.57% | overall: 42.59%\n",
            "k=1 | th=20 | head: 42.41% | tail: 42.50% | overall: 42.46%\n",
            "k=1 | th=30 | head: 42.37% | tail: 42.57% | overall: 42.48%\n",
            "k=1 | th=40 | head: 42.37% | tail: 42.47% | overall: 42.42%\n",
            "k=1 | th=50 | head: 42.33% | tail: 42.36% | overall: 42.35%\n",
            "k=3 | th=3 | head: 46.77% | tail: 45.49% | overall: 46.10%\n",
            "k=3 | th=4 | head: 46.89% | tail: 45.84% | overall: 46.34%\n",
            "k=3 | th=5 | head: 47.17% | tail: 46.16% | overall: 46.64%\n",
            "k=3 | th=6 | head: 47.05% | tail: 46.52% | overall: 46.77%\n",
            "k=3 | th=7 | head: 47.21% | tail: 46.52% | overall: 46.84%\n",
            "k=3 | th=8 | head: 47.40% | tail: 46.70% | overall: 47.03%\n",
            "k=3 | th=9 | head: 47.44% | tail: 46.73% | overall: 47.07%\n",
            "k=3 | th=10 | head: 47.44% | tail: 46.80% | overall: 47.11%\n",
            "k=3 | th=20 | head: 47.76% | tail: 46.59% | overall: 47.14%\n",
            "k=3 | th=30 | head: 47.76% | tail: 46.55% | overall: 47.12%\n",
            "k=3 | th=40 | head: 47.56% | tail: 46.70% | overall: 47.11%\n",
            "k=3 | th=50 | head: 47.52% | tail: 46.80% | overall: 47.14%\n",
            "k=5 | th=5 | head: 48.35% | tail: 47.12% | overall: 47.70%\n",
            "k=5 | th=6 | head: 48.43% | tail: 47.33% | overall: 47.85%\n",
            "k=5 | th=7 | head: 48.74% | tail: 47.55% | overall: 48.11%\n",
            "k=5 | th=8 | head: 48.70% | tail: 47.48% | overall: 48.06%\n",
            "k=5 | th=9 | head: 48.82% | tail: 47.73% | overall: 48.24%\n",
            "k=5 | th=10 | head: 48.82% | tail: 47.83% | overall: 48.30%\n",
            "k=5 | th=20 | head: 48.90% | tail: 48.01% | overall: 48.43%\n",
            "k=5 | th=30 | head: 49.02% | tail: 48.12% | overall: 48.54%\n",
            "k=5 | th=40 | head: 48.98% | tail: 48.33% | overall: 48.64%\n",
            "k=5 | th=50 | head: 48.94% | tail: 48.05% | overall: 48.47%\n",
            "k=10 | th=10 | head: 50.87% | tail: 49.08% | overall: 49.93%\n",
            "k=10 | th=11 | head: 51.30% | tail: 49.29% | overall: 50.24%\n",
            "k=10 | th=12 | head: 51.26% | tail: 49.32% | overall: 50.24%\n",
            "k=10 | th=13 | head: 51.30% | tail: 49.40% | overall: 50.30%\n",
            "k=10 | th=14 | head: 51.26% | tail: 49.40% | overall: 50.28%\n",
            "k=10 | th=15 | head: 51.38% | tail: 49.57% | overall: 50.43%\n",
            "k=10 | th=16 | head: 51.26% | tail: 49.64% | overall: 50.41%\n",
            "k=10 | th=17 | head: 51.34% | tail: 49.57% | overall: 50.41%\n",
            "k=10 | th=18 | head: 51.30% | tail: 49.57% | overall: 50.39%\n",
            "k=10 | th=19 | head: 51.49% | tail: 49.68% | overall: 50.54%\n",
            "k=10 | th=20 | head: 51.46% | tail: 49.72% | overall: 50.54%\n",
            "k=10 | th=30 | head: 51.49% | tail: 50.25% | overall: 50.84%\n",
            "k=10 | th=40 | head: 51.26% | tail: 50.28% | overall: 50.75%\n",
            "k=10 | th=50 | head: 51.14% | tail: 50.28% | overall: 50.69%\n"
          ]
        }
      ],
      "source": [
        "# Define the mapping of k values to their respective threshold lists\n",
        "k_threshold_mapping = {\n",
        "    1: [1,2, 3,4, 5,6,7,8,9,10, 20, 30, 40, 50],\n",
        "    3: [3,4,5,6,7,8,9, 10, 20, 30, 40, 50],\n",
        "    5: [5,6,7,8,9, 10, 20, 30, 40, 50],\n",
        "    10: [10,11,12,13,14,15,16,17,18,19, 20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "# Iterate through the mapping and print results on the fly\n",
        "for k, threshold_values in k_threshold_mapping.items():\n",
        "    for threshold in threshold_values:\n",
        "        # Evaluate for head\n",
        "        total_count_head, hit_count_head = tripleEvaluator.rerank(k=k, model=best_xgb, threshold=threshold, evaluate_for=\"head\")\n",
        "        head_percentage = hit_count_head / total_count_head * 100\n",
        "\n",
        "        # Evaluate for tail\n",
        "        total_count_tail, hit_count_tail = tripleEvaluator.rerank(k=k, model=best_xgb, threshold=threshold, evaluate_for=\"tail\")\n",
        "        tail_percentage = hit_count_tail / total_count_tail * 100\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        overall_hit_count = hit_count_head + hit_count_tail\n",
        "        overall_total_count = total_count_head + total_count_tail\n",
        "        overall_percentage = (overall_hit_count / overall_total_count) * 100\n",
        "\n",
        "        # Print results immediately\n",
        "        print(\n",
        "            f\"k={k} | th={threshold} | \"\n",
        "            f\"head: {head_percentage:.2f}% | tail: {tail_percentage:.2f}% | overall: {overall_percentage:.2f}%\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI-JrkLNPn4D",
        "outputId": "4581613e-2cec-4cd5-a14e-b6f8f1087ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k=1 | th=1 | head: 41.94% | tail: 41.86% | overall: 41.90%\n",
            "k=1 | th=2 | head: 42.64% | tail: 42.15% | overall: 42.38%\n",
            "k=1 | th=3 | head: 43.08% | tail: 42.32% | overall: 42.68%\n",
            "k=1 | th=4 | head: 43.15% | tail: 42.54% | overall: 42.83%\n",
            "k=1 | th=5 | head: 43.19% | tail: 42.75% | overall: 42.96%\n",
            "k=1 | th=6 | head: 43.04% | tail: 43.00% | overall: 43.02%\n",
            "k=1 | th=7 | head: 43.15% | tail: 43.03% | overall: 43.09%\n",
            "k=1 | th=8 | head: 43.08% | tail: 42.96% | overall: 43.02%\n",
            "k=1 | th=9 | head: 43.08% | tail: 43.03% | overall: 43.05%\n",
            "k=1 | th=10 | head: 43.04% | tail: 43.03% | overall: 43.04%\n",
            "k=1 | th=20 | head: 43.08% | tail: 42.82% | overall: 42.94%\n",
            "k=1 | th=30 | head: 43.27% | tail: 42.89% | overall: 43.07%\n",
            "k=1 | th=40 | head: 43.19% | tail: 42.79% | overall: 42.98%\n",
            "k=1 | th=50 | head: 43.23% | tail: 42.82% | overall: 43.02%\n",
            "k=3 | th=3 | head: 46.77% | tail: 45.49% | overall: 46.10%\n",
            "k=3 | th=4 | head: 46.97% | tail: 45.91% | overall: 46.42%\n",
            "k=3 | th=5 | head: 47.25% | tail: 46.20% | overall: 46.70%\n",
            "k=3 | th=6 | head: 47.13% | tail: 46.48% | overall: 46.79%\n",
            "k=3 | th=7 | head: 47.25% | tail: 46.59% | overall: 46.90%\n",
            "k=3 | th=8 | head: 47.32% | tail: 46.59% | overall: 46.94%\n",
            "k=3 | th=9 | head: 47.32% | tail: 46.80% | overall: 47.05%\n",
            "k=3 | th=10 | head: 47.36% | tail: 46.80% | overall: 47.07%\n",
            "k=3 | th=20 | head: 47.25% | tail: 46.84% | overall: 47.03%\n",
            "k=3 | th=30 | head: 47.44% | tail: 46.91% | overall: 47.16%\n",
            "k=3 | th=40 | head: 47.36% | tail: 47.05% | overall: 47.20%\n",
            "k=3 | th=50 | head: 47.44% | tail: 47.05% | overall: 47.24%\n",
            "k=5 | th=5 | head: 48.35% | tail: 47.12% | overall: 47.70%\n",
            "k=5 | th=6 | head: 48.39% | tail: 47.41% | overall: 47.87%\n",
            "k=5 | th=7 | head: 48.62% | tail: 47.44% | overall: 48.00%\n",
            "k=5 | th=8 | head: 48.70% | tail: 47.51% | overall: 48.08%\n",
            "k=5 | th=9 | head: 48.86% | tail: 47.69% | overall: 48.24%\n",
            "k=5 | th=10 | head: 48.94% | tail: 47.80% | overall: 48.34%\n",
            "k=5 | th=20 | head: 49.37% | tail: 48.05% | overall: 48.67%\n",
            "k=5 | th=30 | head: 49.25% | tail: 48.26% | overall: 48.73%\n",
            "k=5 | th=40 | head: 49.25% | tail: 48.47% | overall: 48.84%\n",
            "k=5 | th=50 | head: 49.10% | tail: 48.61% | overall: 48.84%\n",
            "k=10 | th=10 | head: 50.87% | tail: 49.08% | overall: 49.93%\n",
            "k=10 | th=11 | head: 51.22% | tail: 49.25% | overall: 50.19%\n",
            "k=10 | th=12 | head: 51.10% | tail: 49.32% | overall: 50.17%\n",
            "k=10 | th=13 | head: 51.06% | tail: 49.36% | overall: 50.17%\n",
            "k=10 | th=14 | head: 51.14% | tail: 49.47% | overall: 50.26%\n",
            "k=10 | th=15 | head: 51.26% | tail: 49.64% | overall: 50.41%\n",
            "k=10 | th=16 | head: 51.34% | tail: 49.54% | overall: 50.39%\n",
            "k=10 | th=17 | head: 51.46% | tail: 49.57% | overall: 50.47%\n",
            "k=10 | th=18 | head: 51.42% | tail: 49.64% | overall: 50.49%\n",
            "k=10 | th=19 | head: 51.53% | tail: 49.68% | overall: 50.56%\n",
            "k=10 | th=20 | head: 51.69% | tail: 49.61% | overall: 50.60%\n",
            "k=10 | th=30 | head: 52.08% | tail: 50.14% | overall: 51.06%\n",
            "k=10 | th=40 | head: 52.12% | tail: 50.60% | overall: 51.33%\n",
            "k=10 | th=50 | head: 52.05% | tail: 50.85% | overall: 51.42%\n"
          ]
        }
      ],
      "source": [
        "# Define the mapping of k values to their respective threshold lists\n",
        "k_threshold_mapping = {\n",
        "    1: [1,2, 3,4, 5,6,7,8,9,10, 20, 30, 40, 50],\n",
        "    3: [3,4,5,6,7,8,9, 10, 20, 30, 40, 50],\n",
        "    5: [5,6,7,8,9, 10, 20, 30, 40, 50],\n",
        "    10: [10,11,12,13,14,15,16,17,18,19, 20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "# Iterate through the mapping and print results on the fly\n",
        "for k, threshold_values in k_threshold_mapping.items():\n",
        "    for threshold in threshold_values:\n",
        "        # Evaluate for head\n",
        "        total_count_head, hit_count_head = tripleEvaluator.rerank(k=k, model=best_lgbm, threshold=threshold, evaluate_for=\"head\")\n",
        "        head_percentage = hit_count_head / total_count_head * 100\n",
        "\n",
        "        # Evaluate for tail\n",
        "        total_count_tail, hit_count_tail = tripleEvaluator.rerank(k=k, model=best_lgbm, threshold=threshold, evaluate_for=\"tail\")\n",
        "        tail_percentage = hit_count_tail / total_count_tail * 100\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        overall_hit_count = hit_count_head + hit_count_tail\n",
        "        overall_total_count = total_count_head + total_count_tail\n",
        "        overall_percentage = (overall_hit_count / overall_total_count) * 100\n",
        "\n",
        "        # Print results immediately\n",
        "        print(\n",
        "            f\"k={k} | th={threshold} | \"\n",
        "            f\"head: {head_percentage:.2f}% | tail: {tail_percentage:.2f}% | overall: {overall_percentage:.2f}%\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfckpZ0vgt-J",
        "outputId": "9dbbaced-15bb-49be-abbe-358f2bebfd3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k=1 | th=1 | head: 41.94% | tail: 41.86% | overall: 41.90%\n",
            "k=1 | th=2 | head: 42.21% | tail: 41.93% | overall: 42.06%\n",
            "k=1 | th=3 | head: 42.68% | tail: 42.11% | overall: 42.38%\n",
            "k=1 | th=4 | head: 42.80% | tail: 42.32% | overall: 42.55%\n",
            "k=1 | th=5 | head: 42.96% | tail: 42.61% | overall: 42.77%\n",
            "k=1 | th=6 | head: 42.88% | tail: 42.96% | overall: 42.92%\n",
            "k=1 | th=7 | head: 42.88% | tail: 42.96% | overall: 42.92%\n",
            "k=1 | th=8 | head: 42.88% | tail: 42.89% | overall: 42.89%\n",
            "k=1 | th=9 | head: 42.84% | tail: 42.93% | overall: 42.89%\n",
            "k=1 | th=10 | head: 42.84% | tail: 42.86% | overall: 42.85%\n",
            "k=1 | th=20 | head: 42.80% | tail: 42.89% | overall: 42.85%\n",
            "k=1 | th=30 | head: 42.88% | tail: 43.07% | overall: 42.98%\n",
            "k=1 | th=40 | head: 42.88% | tail: 43.11% | overall: 43.00%\n",
            "k=1 | th=50 | head: 42.88% | tail: 43.14% | overall: 43.02%\n",
            "k=3 | th=3 | head: 46.77% | tail: 45.49% | overall: 46.10%\n",
            "k=3 | th=4 | head: 46.85% | tail: 45.74% | overall: 46.27%\n",
            "k=3 | th=5 | head: 47.21% | tail: 45.91% | overall: 46.53%\n",
            "k=3 | th=6 | head: 47.21% | tail: 46.16% | overall: 46.66%\n",
            "k=3 | th=7 | head: 47.44% | tail: 46.38% | overall: 46.88%\n",
            "k=3 | th=8 | head: 47.60% | tail: 46.45% | overall: 46.99%\n",
            "k=3 | th=9 | head: 47.68% | tail: 46.62% | overall: 47.12%\n",
            "k=3 | th=10 | head: 47.76% | tail: 46.59% | overall: 47.14%\n",
            "k=3 | th=20 | head: 47.84% | tail: 46.52% | overall: 47.14%\n",
            "k=3 | th=30 | head: 47.92% | tail: 46.77% | overall: 47.31%\n",
            "k=3 | th=40 | head: 47.88% | tail: 46.98% | overall: 47.40%\n",
            "k=3 | th=50 | head: 47.84% | tail: 47.09% | overall: 47.44%\n",
            "k=5 | th=5 | head: 48.35% | tail: 47.12% | overall: 47.70%\n",
            "k=5 | th=6 | head: 48.23% | tail: 47.30% | overall: 47.74%\n",
            "k=5 | th=7 | head: 48.51% | tail: 47.48% | overall: 47.96%\n",
            "k=5 | th=8 | head: 48.70% | tail: 47.44% | overall: 48.04%\n",
            "k=5 | th=9 | head: 48.86% | tail: 47.62% | overall: 48.21%\n",
            "k=5 | th=10 | head: 48.86% | tail: 47.76% | overall: 48.28%\n",
            "k=5 | th=20 | head: 49.45% | tail: 47.44% | overall: 48.39%\n",
            "k=5 | th=30 | head: 49.61% | tail: 47.94% | overall: 48.73%\n",
            "k=5 | th=40 | head: 49.41% | tail: 48.05% | overall: 48.69%\n",
            "k=5 | th=50 | head: 49.49% | tail: 48.12% | overall: 48.77%\n",
            "k=10 | th=10 | head: 50.87% | tail: 49.08% | overall: 49.93%\n",
            "k=10 | th=11 | head: 51.26% | tail: 49.15% | overall: 50.15%\n",
            "k=10 | th=12 | head: 51.26% | tail: 49.11% | overall: 50.13%\n",
            "k=10 | th=13 | head: 51.30% | tail: 49.18% | overall: 50.19%\n",
            "k=10 | th=14 | head: 51.38% | tail: 49.29% | overall: 50.28%\n",
            "k=10 | th=15 | head: 51.34% | tail: 49.40% | overall: 50.32%\n",
            "k=10 | th=16 | head: 51.30% | tail: 49.43% | overall: 50.32%\n",
            "k=10 | th=17 | head: 51.49% | tail: 49.54% | overall: 50.47%\n",
            "k=10 | th=18 | head: 51.34% | tail: 49.43% | overall: 50.34%\n",
            "k=10 | th=19 | head: 51.46% | tail: 49.43% | overall: 50.39%\n",
            "k=10 | th=20 | head: 51.53% | tail: 49.47% | overall: 50.45%\n",
            "k=10 | th=30 | head: 51.81% | tail: 49.72% | overall: 50.71%\n",
            "k=10 | th=40 | head: 51.69% | tail: 49.82% | overall: 50.71%\n",
            "k=10 | th=50 | head: 51.61% | tail: 50.07% | overall: 50.80%\n"
          ]
        }
      ],
      "source": [
        "# Define the mapping of k values to their respective threshold lists\n",
        "k_threshold_mapping = {\n",
        "    1: [1,2, 3,4, 5,6,7,8,9,10, 20, 30, 40, 50],\n",
        "    3: [3,4,5,6,7,8,9, 10, 20, 30, 40, 50],\n",
        "    5: [5,6,7,8,9, 10, 20, 30, 40, 50],\n",
        "    10: [10,11,12,13,14,15,16,17,18,19, 20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "# Iterate through the mapping and print results on the fly\n",
        "for k, threshold_values in k_threshold_mapping.items():\n",
        "    for threshold in threshold_values:\n",
        "        # Evaluate for head\n",
        "        total_count_head, hit_count_head = tripleEvaluator.rerank(k=k, model=ensemble_model, threshold=threshold, evaluate_for=\"head\")\n",
        "        head_percentage = hit_count_head / total_count_head * 100\n",
        "\n",
        "        # Evaluate for tail\n",
        "        total_count_tail, hit_count_tail = tripleEvaluator.rerank(k=k, model=ensemble_model, threshold=threshold, evaluate_for=\"tail\")\n",
        "        tail_percentage = hit_count_tail / total_count_tail * 100\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        overall_hit_count = hit_count_head + hit_count_tail\n",
        "        overall_total_count = total_count_head + total_count_tail\n",
        "        overall_percentage = (overall_hit_count / overall_total_count) * 100\n",
        "\n",
        "        # Print results immediately\n",
        "        print(\n",
        "            f\"k={k} | th={threshold} | \"\n",
        "            f\"head: {head_percentage:.2f}% | tail: {tail_percentage:.2f}% | overall: {overall_percentage:.2f}%\"\n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
