{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxIZErHduZIK",
        "outputId": "8ba19105-3e40-4884-f05d-e6272c295e57"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,roc_curve,auc,classification_report,make_scorer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzGIB1p89ytc"
      },
      "outputs": [],
      "source": [
        "from link_prediction import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvGS35YXno_Y"
      },
      "outputs": [],
      "source": [
        "#Load the entity embeddings dict\n",
        "with open(\"fb15k237_distmult_entity_embeddings.pkl\", \"rb\") as f:\n",
        "    entity_embeddings = pickle.load(f)\n",
        "#Load the predicate embeddings dict\n",
        "with open(\"fb15k237_distmult_predicate_embeddings.pkl\", \"rb\") as f:\n",
        "    predicate_embeddings = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa2LFenqu9wS"
      },
      "outputs": [],
      "source": [
        "train_triples = pd.read_csv('fb15k237_train.txt', dtype=str, sep='\\t', header=None, names=['head', 'relation', 'tail'])\n",
        "test_triples = pd.read_csv('fb15k237_test.txt', dtype=str, sep='\\t', header=None, names=['head', 'relation', 'tail'])\n",
        "#valid_triples = pd.read_csv('fb15k237_valid.txt', dtype=str, sep='\\t', header=None, names=['head', 'relation', 'tail'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naNbIKQjo40C",
        "outputId": "ddd6b0f2-6419-4e52-b991-b332ee1f3f23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Precomputing top-k predictions: 100%|██████████| 20466/20466 [55:40<00:00,  6.13it/s]\n"
          ]
        }
      ],
      "source": [
        "tripleEvaluator=TripleEvaluator(entity_embeddings,predicate_embeddings,train_triples,test_triples, model='DistMult', k=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6J070kFo5v-",
        "outputId": "dc1e97d0-505c-4c6a-c5d4-53ee6ea3c8ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing triples: 100%|██████████| 272115/272115 [3:23:33<00:00, 22.28triple/s]\n",
            "Processing triples: 100%|██████████| 272115/272115 [4:16:23<00:00, 17.69triple/s]\n"
          ]
        }
      ],
      "source": [
        "#Create or acquire the training data (negative samples)\n",
        "tail_df = tripleEvaluator.create_training_data_filtered(n=1, creating_for=\"tail\")\n",
        "tail_df.to_csv('/content/drive/MyDrive/link_prediction/fb15k237_distmult_tail_df_1_ns.csv', index=False)\n",
        "#tail_df = pd.read_csv('dbpedia50_distmult_tail_df_1_ns.csv')\n",
        "head_df = tripleEvaluator.create_training_data_filtered(n=1, creating_for=\"head\")\n",
        "head_df.to_csv('/content/drive/MyDrive/link_prediction/fb15k237_distmult_head_df_1_ns.csv', index=False)\n",
        "#head_df = pd.read_csv('dbpedia50_distmult_head_df_1_ns.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_9FIvAFFCNy"
      },
      "outputs": [],
      "source": [
        "train_triples['label']=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z8Nz2WLwF0u"
      },
      "outputs": [],
      "source": [
        "train_df = pd.concat([head_df,tail_df,train_triples], axis=0)\n",
        "# Reset the index\n",
        "train_df.reset_index(drop=True, inplace=True)\n",
        "# Drop duplicate rows\n",
        "train_df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "WzTNqTK4FQ4j",
        "outputId": "36d91860-9133-42f6-db60-6972688274bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>272115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>144982</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "1    272115\n",
              "0    144982\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4RXmYKNtxAh"
      },
      "outputs": [],
      "source": [
        "# Step 1: Prepare the training data\n",
        "train_df['embedding'] = train_df.apply(lambda row: tripleEvaluator.get_embedding(row), axis=1)\n",
        "X_train = np.vstack(train_df['embedding'].values)  # Stack embeddings into a matrix\n",
        "y_train = train_df['label'].values  # Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gh7qdLaDHVA"
      },
      "outputs": [],
      "source": [
        "# Step 1: Split the data into training and test sets with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    np.vstack(train_df['embedding'].values),  # Embeddings matrix\n",
        "    train_df['label'].values,                # Labels\n",
        "    test_size=0.1,                           # 10% of the data for testing\n",
        "    random_state=42,                         # For reproducibility\n",
        "    stratify=train_df['label'].values        # Maintain label distribution\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTrGMFhwWfzb",
        "outputId": "d736079f-0210-4a4d-e270-8490eeda1f41"
      },
      "outputs": [],
      "source": [
        "# Step 1: Initialize the MLP model\n",
        "mlp_model = MLPClassifier(\n",
        "    hidden_layer_sizes=(128, 128),  # Two layers with k units each\n",
        "    activation='relu',              # ReLU activation function\n",
        "    solver='adam',                  # Adam optimizer\n",
        "    alpha=0.0001,                   # L2 regularization\n",
        "    learning_rate_init=0.001,       # Learning rate\n",
        "    early_stopping=True,            # Stops if validation score does not improve\n",
        "    max_iter=10,                     # Number of iterations\n",
        "    batch_size=32,                  # Same batch size\n",
        "    random_state=42                 # For reproducibility\n",
        ")\n",
        "mlp_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Evaluate the model on the test set\n",
        "y_pred = mlp_model.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Accuracy on test set:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxAxuk58wyP0",
        "outputId": "98b51f43-dbab-4a07-8540-b193656d7f58"
      },
      "outputs": [],
      "source": [
        "# Create a LightGBM model \n",
        "lgbm_model = LGBMClassifier(\n",
        "    #class_weight={0: 1, 1: 3}, # To handle imbalanced data\n",
        "    n_estimators=100,        # Number of boosting rounds\n",
        "    max_depth=15,            # Maximum depth of a tree\n",
        "    #num_leaves= 100,              # Maximum number of leaves in one tree\n",
        "    #min_child_samples=25 ,       # Minimum data per leaf\n",
        "    #subsample= 1,\n",
        "    random_state=42          # Set a random state for reproducibility\n",
        ")\n",
        "# Fit the model\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_lgbm = lgbm_model.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"LightGBM Classification Report:\\n\", classification_report(y_test, y_pred_lgbm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gCuAPuA0HK_",
        "outputId": "87475fff-a90c-4c59-8eac-d6e177d4a154"
      },
      "outputs": [],
      "source": [
        "# Create an XGBoost model \n",
        "xgb_model = XGBClassifier(\n",
        "    #scale_pos_weight=10,    # Adjust the weight for the positive class (useful for imbalance)\n",
        "    n_estimators=100,       # Number of boosting rounds\n",
        "    max_depth=10,           # Maximum depth of a tree\n",
        "    #min_child_weight=,\n",
        "    #subsample=,\n",
        "    #colsample_bytree=\n",
        "    #scale_pos_weight=3,\n",
        "    random_state=42         # Set a random state for reproducibility\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd9W3fwtZVjd",
        "outputId": "e67a0645-46e5-45c6-c666-9d788b734381"
      },
      "outputs": [],
      "source": [
        "# Create the voting classifier\n",
        "ensemble_model = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_model),\n",
        "        ('lgbm', lgbm_model),\n",
        "        ('mlp', mlp_model)\n",
        "    ],\n",
        "    voting='soft',  # Soft voting to use probabilities\n",
        "    n_jobs=-1       # Use all cores for parallel processing\n",
        ")\n",
        "\n",
        "# Fit the ensemble model (if needed)\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the ensemble\n",
        "y_pred_ensemble = ensemble_model.predict(X_test)\n",
        "\n",
        "print(\"Ensemble Accuracy:\", accuracy_score(y_test, y_pred_ensemble))\n",
        "print(\"Classification Report for Ensemble:\\n\", classification_report(y_test, y_pred_ensemble))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZSKDVJ6ZDNh"
      },
      "source": [
        "**ORIGINIAL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q3MjGjuiCgv",
        "outputId": "f7e7c2de-9cd3-42f6-ad64-b2d72b1f2053"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "\n",
        "# Evaluate for k from 1 to 10 and store the results in a dictionary\n",
        "for k in [1, 3, 5, 10, 20, 30, 40, 50, 100]:\n",
        "    total_count_head, hit_count_head = tripleEvaluator.evaluate_hitk_original_2_on_patterns(k=k, evaluate_for=\"head\")\n",
        "    total_count_tail, hit_count_tail = tripleEvaluator.evaluate_hitk_original_2_on_patterns(k=k, evaluate_for=\"tail\")\n",
        "\n",
        "    overall_hit_count = hit_count_head + hit_count_tail\n",
        "    overall_total_count = total_count_head + total_count_tail\n",
        "    overall_percentage = (overall_hit_count / overall_total_count) * 100\n",
        "\n",
        "    results[k] = {\n",
        "        \"head\": {\n",
        "            \"total_count\": len(tripleEvaluator.precomputed_top_k_head),\n",
        "            \"hit_count\": hit_count_head,\n",
        "            \"percentage\": hit_count_head / total_count_head * 100\n",
        "        },\n",
        "        \"tail\": {\n",
        "            \"total_count\": len(tripleEvaluator.precomputed_top_k_tail),\n",
        "            \"hit_count\": hit_count_tail,\n",
        "            \"percentage\": hit_count_tail / total_count_tail * 100\n",
        "        },\n",
        "        \"overall\": {\n",
        "            \"hit_count\": overall_hit_count,\n",
        "            \"total_count\": overall_total_count,\n",
        "            \"percentage\": overall_percentage\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Print the results nicely\n",
        "for k, data in results.items():\n",
        "    print(\n",
        "        f\"k={k}: \"\n",
        "        f\"Head: {data['head']['percentage']:.2f}% | \"\n",
        "        f\"Tail: {data['tail']['percentage']:.2f}% | \"\n",
        "        f\"Overall: {data['overall']['percentage']:.2f}%\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uILILUuZNl-"
      },
      "source": [
        "**MLP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGr4ioF-R07-",
        "outputId": "98e7ac60-3f6b-4edb-8601-54c20e58cd69"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "# Define the mapping of k values to their respective threshold lists\n",
        "k_threshold_mapping = {\n",
        "    1: [1, 3, 5, 10, 20, 30, 40, 50],\n",
        "    3: [3, 5, 10, 20, 30, 40, 50],\n",
        "    5: [5, 10, 20, 30, 40, 50],\n",
        "    10: [10, 20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "# Iterate through the mapping\n",
        "for k, threshold_values in k_threshold_mapping.items():\n",
        "    for threshold in threshold_values:\n",
        "        # Evaluate for head\n",
        "        total_count_head, hit_count_head = tripleEvaluator.rerank(k=k, model=mlp_model, threshold=threshold, evaluate_for=\"head\")\n",
        "        head_percentage = hit_count_head / total_count_head * 100\n",
        "\n",
        "        # Evaluate for tail\n",
        "        total_count_tail, hit_count_tail = tripleEvaluator.rerank(k=k, model=mlp_model, threshold=threshold, evaluate_for=\"tail\")\n",
        "        tail_percentage = hit_count_tail / total_count_tail * 100\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        overall_hit_count = hit_count_head + hit_count_tail\n",
        "        overall_total_count = total_count_head + total_count_tail\n",
        "        overall_percentage = (overall_hit_count / overall_total_count) * 100\n",
        "\n",
        "        # Store the results in a dictionary\n",
        "        results.append({\n",
        "            \"k\": k,\n",
        "            \"threshold\": threshold,\n",
        "            \"head\": f\"{head_percentage:.2f}%\",\n",
        "            \"tail\": f\"{tail_percentage:.2f}%\",\n",
        "            \"overall\": f\"{overall_percentage:.2f}%\"\n",
        "        })\n",
        "\n",
        "# Print the results in a formatted way\n",
        "for result in results:\n",
        "    print(\n",
        "        f\"k={result['k']} | th={result['threshold']} | \"\n",
        "        f\"head: {result['head']} | tail: {result['tail']} | overall: {result['overall']}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGwVzcm7ZSSU"
      },
      "source": [
        "**XGB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFSJ40k4Y-TB",
        "outputId": "7b89c851-4acd-4af7-df8c-2ffcde84f86a"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "# Define the mapping of k values to their respective threshold lists\n",
        "k_threshold_mapping = {\n",
        "    1: [1, 3, 5, 10, 20, 30, 40, 50],\n",
        "    3: [3, 5, 10, 20, 30, 40, 50],\n",
        "    5: [5, 10, 20, 30, 40, 50],\n",
        "    10: [10, 20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "# Iterate through the mapping\n",
        "for k, threshold_values in k_threshold_mapping.items():\n",
        "    for threshold in threshold_values:\n",
        "        # Evaluate for head\n",
        "        total_count_head, hit_count_head = tripleEvaluator.rerank(k=k, model=xgb_model, threshold=threshold, evaluate_for=\"head\")\n",
        "        head_percentage = hit_count_head / total_count_head * 100\n",
        "\n",
        "        # Evaluate for tail\n",
        "        total_count_tail, hit_count_tail = tripleEvaluator.rerank(k=k, model=xgb_model, threshold=threshold, evaluate_for=\"tail\")\n",
        "        tail_percentage = hit_count_tail / total_count_tail * 100\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        overall_hit_count = hit_count_head + hit_count_tail\n",
        "        overall_total_count = total_count_head + total_count_tail\n",
        "        overall_percentage = (overall_hit_count / overall_total_count) * 100\n",
        "\n",
        "        # Store the results in a dictionary\n",
        "        results.append({\n",
        "            \"k\": k,\n",
        "            \"threshold\": threshold,\n",
        "            \"head\": f\"{head_percentage:.2f}%\",\n",
        "            \"tail\": f\"{tail_percentage:.2f}%\",\n",
        "            \"overall\": f\"{overall_percentage:.2f}%\"\n",
        "        })\n",
        "\n",
        "# Print the results in a formatted way\n",
        "for result in results:\n",
        "    print(\n",
        "        f\"k={result['k']} | th={result['threshold']} | \"\n",
        "        f\"head: {result['head']} | tail: {result['tail']} | overall: {result['overall']}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNOH_58QZWkf"
      },
      "source": [
        "**LGBM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebl-O7y0Zc_g",
        "outputId": "1fe38846-4cbb-4fde-8aa8-d493f9e89cd6"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "# Define the mapping of k values to their respective threshold lists\n",
        "k_threshold_mapping = {\n",
        "    1: [1, 3, 5, 10, 20, 30, 40, 50],\n",
        "    3: [3, 5, 10, 20, 30, 40, 50],\n",
        "    5: [5, 10, 20, 30, 40, 50],\n",
        "    10: [10, 20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "# Iterate through the mapping\n",
        "for k, threshold_values in k_threshold_mapping.items():\n",
        "    for threshold in threshold_values:\n",
        "        # Evaluate for head\n",
        "        total_count_head, hit_count_head = tripleEvaluator.rerank(k=k, model=lgbm_model, threshold=threshold, evaluate_for=\"head\")\n",
        "        head_percentage = hit_count_head / total_count_head * 100\n",
        "\n",
        "        # Evaluate for tail\n",
        "        total_count_tail, hit_count_tail = tripleEvaluator.rerank(k=k, model=lgbm_model, threshold=threshold, evaluate_for=\"tail\")\n",
        "        tail_percentage = hit_count_tail / total_count_tail * 100\n",
        "\n",
        "       # Calculate overall metrics\n",
        "        overall_hit_count = hit_count_head + hit_count_tail\n",
        "        overall_total_count = total_count_head + total_count_tail\n",
        "        overall_percentage = (overall_hit_count / overall_total_count) * 100\n",
        "\n",
        "        # Store the results in a dictionary\n",
        "        results.append({\n",
        "            \"k\": k,\n",
        "            \"threshold\": threshold,\n",
        "            \"head\": f\"{head_percentage:.2f}%\",\n",
        "            \"tail\": f\"{tail_percentage:.2f}%\",\n",
        "            \"overall\": f\"{overall_percentage:.2f}%\"\n",
        "        })\n",
        "\n",
        "# Print the results in a formatted way\n",
        "for result in results:\n",
        "    print(\n",
        "        f\"k={result['k']} | th={result['threshold']} | \"\n",
        "        f\"head: {result['head']} | tail: {result['tail']} | overall: {result['overall']}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctr0UjH9Z6D9"
      },
      "source": [
        "**SCKIT LEARN ENSEMBLE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vbaqPDJaAQA",
        "outputId": "193312f0-ed00-49de-db6e-695632e4df0e"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "# Define the mapping of k values to their respective threshold lists\n",
        "k_threshold_mapping = {\n",
        "    1: [1, 3, 5, 10, 20, 30, 40, 50],\n",
        "    3: [3, 5, 10, 20, 30, 40, 50],\n",
        "    5: [5, 10, 20, 30, 40, 50],\n",
        "    10: [10, 20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "# Iterate through the mapping\n",
        "for k, threshold_values in k_threshold_mapping.items():\n",
        "    for threshold in threshold_values:\n",
        "        # Evaluate for head\n",
        "        total_count_head, hit_count_head = tripleEvaluator.rerank(k=k, model=ensemble_model, threshold=threshold, evaluate_for=\"head\")\n",
        "        head_percentage = hit_count_head / total_count_head * 100\n",
        "\n",
        "        # Evaluate for tail\n",
        "        total_count_tail, hit_count_tail = tripleEvaluator.rerank(k=k, model=ensemble_model, threshold=threshold, evaluate_for=\"tail\")\n",
        "        tail_percentage = hit_count_tail / total_count_tail * 100\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        overall_hit_count = hit_count_head + hit_count_tail\n",
        "        overall_total_count = total_count_head + total_count_tail\n",
        "        overall_percentage = (overall_hit_count / overall_total_count) * 100\n",
        "\n",
        "        # Store the results in a dictionary\n",
        "        results.append({\n",
        "            \"k\": k,\n",
        "            \"threshold\": threshold,\n",
        "            \"head\": f\"{head_percentage:.2f}%\",\n",
        "            \"tail\": f\"{tail_percentage:.2f}%\",\n",
        "            \"overall\": f\"{overall_percentage:.2f}%\"\n",
        "        })\n",
        "\n",
        "# Print the results in a formatted way\n",
        "for result in results:\n",
        "    print(\n",
        "        f\"k={result['k']} | th={result['threshold']} | \"\n",
        "        f\"head: {result['head']} | tail: {result['tail']} | overall: {result['overall']}\"\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
