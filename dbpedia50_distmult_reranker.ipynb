{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5lmmWdct6iL"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxIZErHduZIK",
        "outputId": "46986270-9153-4736-a53b-8f6c5100f303"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,roc_curve,auc,classification_report,make_scorer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import  VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzGIB1p89ytc"
      },
      "outputs": [],
      "source": [
        "from link_prediction import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvGS35YXno_Y"
      },
      "outputs": [],
      "source": [
        "#Load the entity embeddings dict\n",
        "with open(\"dbpedia50_distmult_entity_embeddings.pkl\", \"rb\") as f:\n",
        "    entity_embeddings = pickle.load(f)\n",
        "#Load the predicate embeddings dict\n",
        "with open(\"dbpedia50_distmult_predicate_embeddings.pkl\", \"rb\") as f:\n",
        "    predicate_embeddings = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa2LFenqu9wS"
      },
      "outputs": [],
      "source": [
        "train_triples = pd.read_csv('dbpedia50_train.csv', dtype=str)\n",
        "#val_triples = pd.read_csv('dbpedia50_valid.csv',dtype=str)\n",
        "test_triples = pd.read_csv('dbpedia50_test_filtered.csv', dtype=str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_9FIvAFFCNy"
      },
      "outputs": [],
      "source": [
        "train_triples['label']=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Z8Nz2WLwF0u"
      },
      "outputs": [],
      "source": [
        "# Read the CSV files\n",
        "head_df = pd.read_csv('dbpedia50_distmult_head_df_1_ns.csv')\n",
        "#head_df = head_df.drop(index=0).reset_index(drop=True)  # Resetting the index after dropping\n",
        "tail_df = pd.read_csv('dbpedia50_distmult_tail_df_1_ns.csv')\n",
        "#tail_df = tail_df.drop(index=0).reset_index(drop=True)  # Resetting the index after dropping\n",
        "# Combine the datasets by concatenating them along rows (axis=0)\n",
        "train_df = pd.concat([head_df,tail_df,train_triples], axis=0)\n",
        "# Reset the index\n",
        "train_df.reset_index(drop=True, inplace=True)\n",
        "# Drop duplicate rows\n",
        "train_df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "6W_AMQttMgev",
        "outputId": "3a390fa1-f096-41c1-db60-0ac61025e857"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32203</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "0    40014\n",
              "1    32203\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riy1Jjd90eBe",
        "outputId": "c21b155b-957f-4afb-ebb1-e5ed76ac0996"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Precomputing top-k predictions: 100%|██████████| 2098/2098 [09:09<00:00,  3.82it/s]\n"
          ]
        }
      ],
      "source": [
        "tripleEvaluator=TripleEvaluator(entity_embeddings,predicate_embeddings,train_triples,test_triples, model='DistMult', k=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4RXmYKNtxAh"
      },
      "outputs": [],
      "source": [
        "# Step 1: Prepare the training data\n",
        "train_df['embedding'] = train_df.apply(lambda row: tripleEvaluator.get_embedding(row), axis=1)\n",
        "X_train = np.vstack(train_df['embedding'].values)  # Stack embeddings into a matrix\n",
        "y_train = train_df['label'].values  # Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gh7qdLaDHVA"
      },
      "outputs": [],
      "source": [
        "# Step 1: Split the data into training and test sets with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    np.vstack(train_df['embedding'].values),  # Embeddings matrix\n",
        "    train_df['label'].values,                # Labels\n",
        "    test_size=0.1,                           # 10% of the data for testing\n",
        "    random_state=42,                         # For reproducibility\n",
        "    stratify=train_df['label'].values        # Maintain label distribution\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTrGMFhwWfzb",
        "outputId": "06ff04ca-f3fc-404b-88f7-cb2967d6d3ca"
      },
      "outputs": [],
      "source": [
        "# Step 1: Initialize the MLP model\n",
        "mlp_model = MLPClassifier(\n",
        "    hidden_layer_sizes=(128, 128),  # Two layers with k units each\n",
        "    activation='relu',              # ReLU activation function\n",
        "    solver='adam',                  # Adam optimizer\n",
        "    alpha=0.0001,                   # L2 regularization\n",
        "    learning_rate_init=0.001,       # Learning rate\n",
        "    early_stopping=True,            # Stops if validation score does not improve\n",
        "    max_iter=25,                     # Number of iterations\n",
        "    batch_size=32,                  # Same batch size\n",
        "    random_state=42                 # For reproducibility\n",
        ")\n",
        "mlp_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Evaluate the model on the test set\n",
        "y_pred = mlp_model.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Accuracy on test set:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9StH5M-FyG8k",
        "outputId": "defc342e-1b5e-4672-9f5b-acb219d31e2f"
      },
      "outputs": [],
      "source": [
        "# Create an XGBoost model \n",
        "xgb_model = XGBClassifier(\n",
        "    #scale_pos_weight=2,    # Adjust the weight for the positive class (useful for imbalance)\n",
        "    n_estimators=100,       # Number of boosting rounds\n",
        "    max_depth=10,           # Maximum depth of a tree\n",
        "    #min_child_weight=,\n",
        "    #subsample=,\n",
        "    #colsample_bytree=\n",
        "    random_state=42         # Set a random state for reproducibility\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxAxuk58wyP0",
        "outputId": "2fd430c8-8383-403d-beaf-f84e4bdf72f5"
      },
      "outputs": [],
      "source": [
        "# Create a LightGBM model\n",
        "lgbm_model = LGBMClassifier(\n",
        "    #class_weight={0: 1, 1: 2}, # To handle imbalanced data\n",
        "    n_estimators=100,        # Number of boosting rounds\n",
        "    max_depth=15,            # Maximum depth of a tree\n",
        "    #num_leaves= 100,              # Maximum number of leaves in one tree\n",
        "    #min_child_samples=25 ,       # Minimum data per leaf\n",
        "    #subsample= 1,\n",
        "    random_state=42          # Set a random state for reproducibility\n",
        ")\n",
        "# Fit the model\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_lgbm = lgbm_model.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"LightGBM Classification Report:\\n\", classification_report(y_test, y_pred_lgbm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd9W3fwtZVjd",
        "outputId": "d9fbd92a-b68c-4efd-cd27-404d31842271"
      },
      "outputs": [],
      "source": [
        "# Create the voting classifier\n",
        "ensemble_model = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('xgb', xgb_model),\n",
        "        ('mlp', mlp_model),\n",
        "        ('lgbm', lgbm_model)\n",
        "    ],\n",
        "    voting='soft',  # Soft voting to use probabilities\n",
        "    n_jobs=-1       # Use all cores for parallel processing\n",
        ")\n",
        "\n",
        "# Fit the ensemble model (if needed)\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the ensemble\n",
        "y_pred_ensemble = ensemble_model.predict(X_test)\n",
        "\n",
        "print(\"Ensemble Accuracy:\", accuracy_score(y_test, y_pred_ensemble))\n",
        "print(\"Classification Report for Ensemble:\\n\", classification_report(y_test, y_pred_ensemble))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZSKDVJ6ZDNh"
      },
      "source": [
        "**ORIGINIAL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnAgNjLw3Ff5",
        "outputId": "5f5a3b09-580e-4db5-8101-9313f7f1b27a"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "\n",
        "# Evaluate for k from 1 to 10 and store the results in a dictionary\n",
        "for k in [1, 3, 5, 10, 20, 30, 40, 50, 100]:\n",
        "    total_count_head, hit_count_head = tripleEvaluator.evaluate_hitk_original_2_on_patterns(k=k, evaluate_for=\"head\")\n",
        "    total_count_tail, hit_count_tail = tripleEvaluator.evaluate_hitk_original_2_on_patterns(k=k, evaluate_for=\"tail\")\n",
        "\n",
        "    overall_hit_count = hit_count_head + hit_count_tail\n",
        "    overall_total_count = total_count_head + total_count_tail\n",
        "    overall_percentage = (overall_hit_count / overall_total_count) * 100\n",
        "\n",
        "    results[k] = {\n",
        "        \"head\": {\n",
        "            \"total_count\": len(tripleEvaluator.precomputed_top_k_head),\n",
        "            \"hit_count\": hit_count_head,\n",
        "            \"percentage\": hit_count_head / total_count_head * 100\n",
        "        },\n",
        "        \"tail\": {\n",
        "            \"total_count\": len(tripleEvaluator.precomputed_top_k_tail),\n",
        "            \"hit_count\": hit_count_tail,\n",
        "            \"percentage\": hit_count_tail / total_count_tail * 100\n",
        "        },\n",
        "        \"overall\": {\n",
        "            \"hit_count\": overall_hit_count,\n",
        "            \"total_count\": overall_total_count,\n",
        "            \"percentage\": overall_percentage\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Print the results nicely\n",
        "for k, data in results.items():\n",
        "    print(\n",
        "        f\"k={k}: \"\n",
        "        f\"Head: {data['head']['percentage']:.2f}% | \"\n",
        "        f\"Tail: {data['tail']['percentage']:.2f}% | \"\n",
        "        f\"Overall: {data['overall']['percentage']:.2f}%\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uILILUuZNl-"
      },
      "source": [
        "**MLP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGr4ioF-R07-",
        "outputId": "fab85b91-3bd3-4742-ceda-c1c092ae180d"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "# Define the mapping of k values to their respective threshold lists\n",
        "k_threshold_mapping = {\n",
        "    1: [1, 3, 5, 10, 20, 30, 40, 50],\n",
        "    3: [3, 5, 10, 20, 30, 40, 50],\n",
        "    5: [5, 10, 20, 30, 40, 50],\n",
        "    10: [10, 20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "# Iterate through the mapping\n",
        "for k, threshold_values in k_threshold_mapping.items():\n",
        "    for threshold in threshold_values:\n",
        "        # Evaluate for head\n",
        "        total_count_head, hit_count_head = tripleEvaluator.rerank(k=k, model=mlp_model, threshold=threshold, evaluate_for=\"head\")\n",
        "        head_percentage = hit_count_head / total_count_head * 100\n",
        "\n",
        "        # Evaluate for tail\n",
        "        total_count_tail, hit_count_tail = tripleEvaluator.rerank(k=k, model=mlp_model, threshold=threshold, evaluate_for=\"tail\")\n",
        "        tail_percentage = hit_count_tail / total_count_tail * 100\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        overall_hit_count = hit_count_head + hit_count_tail\n",
        "        overall_total_count = total_count_head + total_count_tail\n",
        "        overall_percentage = (overall_hit_count / overall_total_count) * 100\n",
        "\n",
        "        # Store the results in a dictionary\n",
        "        results.append({\n",
        "            \"k\": k,\n",
        "            \"threshold\": threshold,\n",
        "            \"head\": f\"{head_percentage:.2f}%\",\n",
        "            \"tail\": f\"{tail_percentage:.2f}%\",\n",
        "            \"overall\": f\"{overall_percentage:.2f}%\"\n",
        "        })\n",
        "\n",
        "# Print the results in a formatted way\n",
        "for result in results:\n",
        "    print(\n",
        "        f\"k={result['k']} | th={result['threshold']} | \"\n",
        "        f\"head: {result['head']} | tail: {result['tail']} | overall: {result['overall']}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGwVzcm7ZSSU"
      },
      "source": [
        "**XGB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFSJ40k4Y-TB",
        "outputId": "80740680-2415-45d0-bba0-78e40202880e"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "# Define the mapping of k values to their respective threshold lists\n",
        "k_threshold_mapping = {\n",
        "    1: [1, 3, 5, 10, 20, 30, 40, 50],\n",
        "    3: [3, 5, 10, 20, 30, 40, 50],\n",
        "    5: [5, 10, 20, 30, 40, 50],\n",
        "    10: [10, 20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "# Iterate through the mapping\n",
        "for k, threshold_values in k_threshold_mapping.items():\n",
        "    for threshold in threshold_values:\n",
        "        # Evaluate for head\n",
        "        total_count_head, hit_count_head = tripleEvaluator.rerank(k=k, model=xgb_model, threshold=threshold, evaluate_for=\"head\")\n",
        "        head_percentage = hit_count_head / total_count_head * 100\n",
        "\n",
        "        # Evaluate for tail\n",
        "        total_count_tail, hit_count_tail = tripleEvaluator.rerank(k=k, model=xgb_model, threshold=threshold, evaluate_for=\"tail\")\n",
        "        tail_percentage = hit_count_tail / total_count_tail * 100\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        overall_hit_count = hit_count_head + hit_count_tail\n",
        "        overall_total_count = total_count_head + total_count_tail\n",
        "        overall_percentage = (overall_hit_count / overall_total_count) * 100\n",
        "\n",
        "        # Store the results in a dictionary\n",
        "        results.append({\n",
        "            \"k\": k,\n",
        "            \"threshold\": threshold,\n",
        "            \"head\": f\"{head_percentage:.2f}%\",\n",
        "            \"tail\": f\"{tail_percentage:.2f}%\",\n",
        "            \"overall\": f\"{overall_percentage:.2f}%\"\n",
        "        })\n",
        "\n",
        "# Print the results in a formatted way\n",
        "for result in results:\n",
        "    print(\n",
        "        f\"k={result['k']} | th={result['threshold']} | \"\n",
        "        f\"head: {result['head']} | tail: {result['tail']} | overall: {result['overall']}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNOH_58QZWkf"
      },
      "source": [
        "**LGBM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebl-O7y0Zc_g",
        "outputId": "c1cf48bf-7cd7-4940-c321-1b97aef37728"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "# Define the mapping of k values to their respective threshold lists\n",
        "k_threshold_mapping = {\n",
        "    1: [1, 3, 5, 10, 20, 30, 40, 50],\n",
        "    3: [3, 5, 10, 20, 30, 40, 50],\n",
        "    5: [5, 10, 20, 30, 40, 50],\n",
        "    10: [10, 20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "# Iterate through the mapping\n",
        "for k, threshold_values in k_threshold_mapping.items():\n",
        "    for threshold in threshold_values:\n",
        "        # Evaluate for head\n",
        "        total_count_head, hit_count_head = tripleEvaluator.rerank(k=k, model=lgbm_model, threshold=threshold, evaluate_for=\"head\")\n",
        "        head_percentage = hit_count_head / total_count_head * 100\n",
        "\n",
        "        # Evaluate for tail\n",
        "        total_count_tail, hit_count_tail = tripleEvaluator.rerank(k=k, model=lgbm_model, threshold=threshold, evaluate_for=\"tail\")\n",
        "        tail_percentage = hit_count_tail / total_count_tail * 100\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        overall_hit_count = hit_count_head + hit_count_tail\n",
        "        overall_total_count = total_count_head + total_count_tail\n",
        "        overall_percentage = (overall_hit_count / overall_total_count) * 100\n",
        "\n",
        "        # Store the results in a dictionary\n",
        "        results.append({\n",
        "            \"k\": k,\n",
        "            \"threshold\": threshold,\n",
        "            \"head\": f\"{head_percentage:.2f}%\",\n",
        "            \"tail\": f\"{tail_percentage:.2f}%\",\n",
        "            \"overall\": f\"{overall_percentage:.2f}%\"\n",
        "        })\n",
        "\n",
        "# Print the results in a formatted way\n",
        "for result in results:\n",
        "    print(\n",
        "        f\"k={result['k']} | th={result['threshold']} | \"\n",
        "        f\"head: {result['head']} | tail: {result['tail']} | overall: {result['overall']}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctr0UjH9Z6D9"
      },
      "source": [
        "**SCKIT LEARN ENSEMBLE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vbaqPDJaAQA",
        "outputId": "303acd40-6327-4810-f814-edd8e0bb2115"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "# Define the mapping of k values to their respective threshold lists\n",
        "k_threshold_mapping = {\n",
        "    1: [1, 3, 5, 10, 20, 30, 40, 50],\n",
        "    3: [3, 5, 10, 20, 30, 40, 50],\n",
        "    5: [5, 10, 20, 30, 40, 50],\n",
        "    10: [10, 20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "# Iterate through the mapping\n",
        "for k, threshold_values in k_threshold_mapping.items():\n",
        "    for threshold in threshold_values:\n",
        "        # Evaluate for head\n",
        "        total_count_head, hit_count_head = tripleEvaluator.rerank(k=k, model=ensemble_model, threshold=threshold, evaluate_for=\"head\")\n",
        "        head_percentage = hit_count_head / total_count_head * 100\n",
        "\n",
        "        # Evaluate for tail\n",
        "        total_count_tail, hit_count_tail = tripleEvaluator.rerank(k=k, model=ensemble_model, threshold=threshold, evaluate_for=\"tail\")\n",
        "        tail_percentage = hit_count_tail / total_count_tail * 100\n",
        "\n",
        "        # Calculate overall metrics\n",
        "        overall_hit_count = hit_count_head + hit_count_tail\n",
        "        overall_total_count = total_count_head + total_count_tail\n",
        "        overall_percentage = (overall_hit_count / overall_total_count) * 100\n",
        "\n",
        "        # Store the results in a dictionary\n",
        "        results.append({\n",
        "            \"k\": k,\n",
        "            \"threshold\": threshold,\n",
        "            \"head\": f\"{head_percentage:.2f}%\",\n",
        "            \"tail\": f\"{tail_percentage:.2f}%\",\n",
        "            \"overall\": f\"{overall_percentage:.2f}%\"\n",
        "        })\n",
        "\n",
        "# Print the results in a formatted way\n",
        "for result in results:\n",
        "    print(\n",
        "        f\"k={result['k']} | th={result['threshold']} | \"\n",
        "        f\"head: {result['head']} | tail: {result['tail']} | overall: {result['overall']}\"\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
